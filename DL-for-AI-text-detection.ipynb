{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1bd43b7-2a29-45a5-9085-9b580cc1c88e"
   },
   "source": [
    "# Deep learning for AI detection\n",
    "\n",
    "The purpose of this project is to show how machine learning methods can be used to identify AI-generated text.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "I generated all the AI text using the GPT-3.5 Turbo API, and compiled the human text from a variety of online sources. There are three different styles of writing in the testing and training data:\n",
    "1. Opinion/argumentation: the human texts comprised a selection of IMDB reviews compiled by the Andrew Maas group at the Stanford AI lab, the AI texts comprised responses from the GPT-3.5 Turbo API upon prompting to write reviews on 410 movies consisting of the top 10 films by US box office in the years 1980-2020.<br>\n",
    "The prompts used were:<br>\n",
    "   *Please write a [positive, negative, mildly positive, mildly negative, neutral] review about the [YEAR] movie [MOVIE] from the perspective of a casual moviegoer[, without mentioning the name of the movie, the name of the director, the year of release, or using the phrase 'casual moviegoer.']*\n",
    "2. Narrative/creative writing: the human texts comprised original Reddit posts in the r/relationship_advice and r/AITA subreddits, which consisted of a mixture of presumably real life stories and fantasy, and the AI texts comprised responses from the GPT-3.5 Turbo API upon prompting to write Reddit posts with the same titles.<br>The prompts used were:<br>\n",
    "*Please write a post in the r/[AITA,relationship_advice] subreddit with the following title: [TITLE]*\n",
    "3. Informative: the human texts comprised the introductory paragraphs of 4023 wikipedia articles selected at random, covering a wide variety of topics (biographical, political, historical, scientific, sports and entertainment), the AI texts comprised responses from GPT-3.5 Turbo API upon prompting to write an encyclopedia-style introduction to the topic.<br>The prompts used were:<br>\n",
    "*Please write a wikipedia-style introduction to the following topic of approximately 600 words, without sections or a concluding or summary sentence: [TITLE]*\n",
    "\n",
    "Details of the data wrangling used to prepare the data for machine learning and the train-test split can be found in a separate notebook (data_wrangling.ipynb)\n",
    "\n",
    "## Import the data, libraries, generate training/validation split\n",
    "Let's import the training data, and split it into a training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:35.876809Z",
     "iopub.status.busy": "2024-02-05T00:54:35.876388Z",
     "iopub.status.idle": "2024-02-05T00:54:35.881820Z",
     "shell.execute_reply": "2024-02-05T00:54:35.880768Z",
     "shell.execute_reply.started": "2024-02-05T00:54:35.876766Z"
    },
    "id": "qWfapOlVaKMc",
    "outputId": "eadf1fb5-1044-489e-81d7-fdce7b60461b"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "home = '/kaggle/input/ml-for-author-identification-train-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:35.893845Z",
     "iopub.status.busy": "2024-02-05T00:54:35.893561Z",
     "iopub.status.idle": "2024-02-05T00:54:37.064473Z",
     "shell.execute_reply": "2024-02-05T00:54:37.063513Z",
     "shell.execute_reply.started": "2024-02-05T00:54:35.893820Z"
    },
    "id": "92ba2302-f035-4dcf-af89-1aa43b43a16e",
    "outputId": "17171a12-e55b-4181-f166-755134e521d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>TTV split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't honestly believe that this is a sequel...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20th Century Fox's ROAD HOUSE 1948) is not onl...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a fan of Jess Franco's bizarre style, and...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(No need to recap the plot, since others have ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I ticked the \"contains spoiler\" box, in case I...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19426</th>\n",
       "      <td>The Louisville Cardinals men's soccer team is ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Louisville Cardinals men's soccer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19427</th>\n",
       "      <td>KFC Yum! Center, also known as the Yum! Center...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>KFC Yum! Center</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19428</th>\n",
       "      <td>The 2020–21 Louisville Cardinals men's basketb...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>2020–21 Louisville Cardinals men's basketball ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19429</th>\n",
       "      <td>Conte Forum is a multi-purpose indoor arena lo...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Conte Forum</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19430</th>\n",
       "      <td>Leary Field is a public recreational park and ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Leary Field</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15588 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            source  \\\n",
       "0      I can't honestly believe that this is a sequel...              imdb   \n",
       "1      20th Century Fox's ROAD HOUSE 1948) is not onl...              imdb   \n",
       "2      I am a fan of Jess Franco's bizarre style, and...              imdb   \n",
       "3      (No need to recap the plot, since others have ...              imdb   \n",
       "4      I ticked the \"contains spoiler\" box, in case I...              imdb   \n",
       "...                                                  ...               ...   \n",
       "19426  The Louisville Cardinals men's soccer team is ...  wikipedia by GPT   \n",
       "19427  KFC Yum! Center, also known as the Yum! Center...  wikipedia by GPT   \n",
       "19428  The 2020–21 Louisville Cardinals men's basketb...  wikipedia by GPT   \n",
       "19429  Conte Forum is a multi-purpose indoor arena lo...  wikipedia by GPT   \n",
       "19430  Leary Field is a public recreational park and ...  wikipedia by GPT   \n",
       "\n",
       "                                                   topic  TTV split  label  \n",
       "0                                           movie review        1.0      0  \n",
       "1                                           movie review        4.0      0  \n",
       "2                                           movie review        2.0      0  \n",
       "3                                           movie review        3.0      0  \n",
       "4                                           movie review        3.0      0  \n",
       "...                                                  ...        ...    ...  \n",
       "19426                  Louisville Cardinals men's soccer        4.0      1  \n",
       "19427                                    KFC Yum! Center        4.0      1  \n",
       "19428  2020–21 Louisville Cardinals men's basketball ...        4.0      1  \n",
       "19429                                        Conte Forum        4.0      1  \n",
       "19430                                        Leary Field        4.0      1  \n",
       "\n",
       "[15588 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>TTV split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With the death of her infirmed husband, May, a...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Spider-Man is in my opinion the best superhero...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Diora Baird is absolutely hot as hell in this ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Family Guy is THE best show on TV. EVER. It ha...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Straight to the point: \"The Groove Tube\" is on...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16735</th>\n",
       "      <td>Floating licensing is a software licensing mod...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Floating licensing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16736</th>\n",
       "      <td>Software copyright refers to the legal protect...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Software copyright</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16737</th>\n",
       "      <td>The Indian Copyright Act is a legislation that...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Indian Copyright Act</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16738</th>\n",
       "      <td>The Copyright law of France represents a funda...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Copyright law of France</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739</th>\n",
       "      <td>The Copyright Law of Germany governs the prote...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Copyright law of Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3843 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            source  \\\n",
       "6      With the death of her infirmed husband, May, a...              imdb   \n",
       "23     Spider-Man is in my opinion the best superhero...              imdb   \n",
       "27     Diora Baird is absolutely hot as hell in this ...              imdb   \n",
       "32     Family Guy is THE best show on TV. EVER. It ha...              imdb   \n",
       "34     Straight to the point: \"The Groove Tube\" is on...              imdb   \n",
       "...                                                  ...               ...   \n",
       "16735  Floating licensing is a software licensing mod...  wikipedia by GPT   \n",
       "16736  Software copyright refers to the legal protect...  wikipedia by GPT   \n",
       "16737  The Indian Copyright Act is a legislation that...  wikipedia by GPT   \n",
       "16738  The Copyright law of France represents a funda...  wikipedia by GPT   \n",
       "16739  The Copyright Law of Germany governs the prote...  wikipedia by GPT   \n",
       "\n",
       "                          topic  TTV split  label  \n",
       "6                  movie review        0.0      0  \n",
       "23                 movie review        0.0      0  \n",
       "27                 movie review        0.0      0  \n",
       "32                 movie review        0.0      0  \n",
       "34                 movie review        0.0      0  \n",
       "...                         ...        ...    ...  \n",
       "16735        Floating licensing        0.0      1  \n",
       "16736        Software copyright        0.0      1  \n",
       "16737      Indian Copyright Act        0.0      1  \n",
       "16738   Copyright law of France        0.0      1  \n",
       "16739  Copyright law of Germany        0.0      1  \n",
       "\n",
       "[3843 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_samples = pd.read_csv(home + 'train.csv')\n",
    "\n",
    "train = train_samples[train_samples['TTV split'] != 0]\n",
    "val = train_samples[train_samples['TTV split'] == 0]\n",
    "\n",
    "display(train)\n",
    "display(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70fdfcac-7006-4fa9-b398-5048f735afe8"
   },
   "source": [
    "Next we import the libraries required for deep learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:37.066429Z",
     "iopub.status.busy": "2024-02-05T00:54:37.066109Z",
     "iopub.status.idle": "2024-02-05T00:54:37.075554Z",
     "shell.execute_reply": "2024-02-05T00:54:37.074582Z",
     "shell.execute_reply.started": "2024-02-05T00:54:37.066402Z"
    },
    "id": "5af39a50-1779-42fc-8a72-a3e6dec4f9d7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping,Callback,ModelCheckpoint,LearningRateScheduler\n",
    "from tensorflow.keras.saving import load_model\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe010521-26cd-4733-883d-c8fc0a59fd4f"
   },
   "source": [
    "The first layer of text processing will be byte-pair encoding (BPE). We will train a BPE tokenizer on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:37.077104Z",
     "iopub.status.busy": "2024-02-05T00:54:37.076736Z",
     "iopub.status.idle": "2024-02-05T00:54:41.465729Z",
     "shell.execute_reply": "2024-02-05T00:54:41.464789Z",
     "shell.execute_reply.started": "2024-02-05T00:54:37.077067Z"
    },
    "id": "8fc96c20-5dda-47af-8e39-d8b9a40a75e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "BPE_tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "BPE_tokenizer.pre_tokenizer = Whitespace()\n",
    "BPE_tokenizer.train_from_iterator(train['text'], trainer=trainer)\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [str(t) for t in BPE_tokenizer.encode(text).ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:41.468369Z",
     "iopub.status.busy": "2024-02-05T00:54:41.468092Z",
     "iopub.status.idle": "2024-02-05T00:54:41.475022Z",
     "shell.execute_reply": "2024-02-05T00:54:41.474020Z",
     "shell.execute_reply.started": "2024-02-05T00:54:41.468345Z"
    },
    "id": "30246d5f-b0a9-4389-8710-ff54f28471ed",
    "outputId": "2c66281d-55b8-42c5-d14e-4b19c6723e89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7467', '3062', '1742', '16', '45', '1711', '1810', '69', '4133', '18']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('Please believe me, I am not a cat.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45325609-e56c-457a-837a-b46269da5d92"
   },
   "source": [
    "We will create a vectorizer layer that takes the tokenized texts as input and transforms it into an appropriate form for input to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:41.476795Z",
     "iopub.status.busy": "2024-02-05T00:54:41.476475Z",
     "iopub.status.idle": "2024-02-05T00:54:41.484837Z",
     "shell.execute_reply": "2024-02-05T00:54:41.484052Z",
     "shell.execute_reply.started": "2024-02-05T00:54:41.476764Z"
    },
    "id": "00c39eac-16fb-4744-9424-2396f0f80f9e"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "seq_length = 2048\n",
    "\n",
    "def create_vectorizer(corpus):\n",
    "    vocab = Counter(corpus.split())\n",
    "    vocab_list = vocab.keys()\n",
    "    text_dataset = tf.data.Dataset.from_tensor_slices(vocab_list)\n",
    "    vocab_size = len(vocab_list)+1\n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=None,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=seq_length,\n",
    "        standardize = None)\n",
    "\n",
    "    vectorize_layer.adapt(text_dataset)\n",
    "    return vectorize_layer,vocab,vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "964d2e27-e765-4d99-8716-8aceb33a4c72"
   },
   "source": [
    "Next we tokenize the training samples and train our vectorizer layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:54:41.486591Z",
     "iopub.status.busy": "2024-02-05T00:54:41.486221Z",
     "iopub.status.idle": "2024-02-05T00:55:03.048503Z",
     "shell.execute_reply": "2024-02-05T00:55:03.047511Z",
     "shell.execute_reply.started": "2024-02-05T00:54:41.486560Z"
    },
    "id": "ff351ec2-5a84-4510-8582-41ad74c34d12",
    "outputId": "7a791ce8-08a2-4787-9a09-f646d2aa1fce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 0 ns, total: 21.5 s\n",
      "Wall time: 21.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train['tokenized'] = train['text'].apply(lambda x: ' '.join(tokenizer(x)))\n",
    "val['tokenized'] = val['text'].apply(lambda x: ' '.join(tokenizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:55:03.050195Z",
     "iopub.status.busy": "2024-02-05T00:55:03.049824Z",
     "iopub.status.idle": "2024-02-05T00:56:02.298625Z",
     "shell.execute_reply": "2024-02-05T00:56:02.297665Z",
     "shell.execute_reply.started": "2024-02-05T00:55:03.050161Z"
    },
    "id": "a34b883a-6f15-4582-b3af-7d0d17cfda53",
    "outputId": "6f82cd59-f5fb-4078-9d54-520bbf6a3d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 29327\n",
      "CPU times: user 1min 24s, sys: 13 s, total: 1min 37s\n",
      "Wall time: 59.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorize_layer,vocab,vocab_size = create_vectorizer(' '.join(train['tokenized']))\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "667b0b2c-a3a1-4152-ae02-5adcc6189f31"
   },
   "source": [
    "We will use our vectorizer layer to vectorize the text inputs and one-hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:02.300345Z",
     "iopub.status.busy": "2024-02-05T00:56:02.299998Z",
     "iopub.status.idle": "2024-02-05T00:56:05.820767Z",
     "shell.execute_reply": "2024-02-05T00:56:05.819690Z",
     "shell.execute_reply.started": "2024-02-05T00:56:02.300318Z"
    },
    "id": "7dff4db6-bece-42be-8536-e30d550715ce",
    "outputId": "e7c681f2-98ff-44b8-c852-cb018693d19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 s, sys: 943 ms, total: 3.27 s\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train = vectorize_layer(train['tokenized'].tolist()).numpy()\n",
    "X_val = vectorize_layer(val['tokenized'].tolist()).numpy()\n",
    "\n",
    "y_train = np.array(train['label'].map({0: [1,0], 1: [0,1]}).tolist())\n",
    "y_val = np.array(val['label'].map({0: [1,0], 1: [0,1]}).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33da7d5a-d775-44ec-a6d7-a8dadad277c2"
   },
   "source": [
    "We will now explore models consisting of an embedding layer, either a single feedforward layer or a single LSTM, and either no attention layer or an attention layer implementing scaled dot product or soft attention. I use dropout to regularize the model during training. There are three hyperparameters: the embedding dimension, the number of units in the feedforward or LSTM layers, and the dropout rate. The memory and time requirements are significantly higher when an LSTM layer is present, when the embedding dimension or number of units is higher, and when an attention mechanism is implemented. For the values of the embedding dimension and number of units I will use both 16 and 64, except in the case of LSTMs with attention, in which case I will fix them both to the lower value of 16 due to memory limitations.\n",
    "\n",
    "I will use the validation data to perform hyperparameter tuning and model selection: I fit the models for a maximum of 100 epochs, but stop fitting early based on monitoring the validation loss. Since the validation loss does not necessarily monotonically increase after the minimum has been reached, I will allow a \"patience\" of ten epochs (i.e. stop the fitting if the validation loss has not improved for the previous ten epochs) and save the model with the best validation loss. This will require careful learning rate scheduling in order to ensure that we reach the minimum validation loss, and that it does not too quickly rapidly increase in the succeeding epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:05.822468Z",
     "iopub.status.busy": "2024-02-05T00:56:05.822064Z",
     "iopub.status.idle": "2024-02-05T00:56:05.835638Z",
     "shell.execute_reply": "2024-02-05T00:56:05.834255Z",
     "shell.execute_reply.started": "2024-02-05T00:56:05.822430Z"
    },
    "id": "35a5920a-029a-4ff0-925e-043913350e45"
   },
   "outputs": [],
   "source": [
    "from tensorflow import math, matmul, reshape, shape, transpose, cast, float32\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class SoftAttention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(SoftAttention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1),\n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1),\n",
    "                               initializer='zeros', trainable=True)\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        alpha = K.softmax(e)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "class ScaledDotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "        weights = K.softmax(scores)\n",
    "        return matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:05.839693Z",
     "iopub.status.busy": "2024-02-05T00:56:05.839272Z",
     "iopub.status.idle": "2024-02-05T00:56:05.855147Z",
     "shell.execute_reply": "2024-02-05T00:56:05.854125Z",
     "shell.execute_reply.started": "2024-02-05T00:56:05.839647Z"
    },
    "id": "8d6ee436-5980-4344-b8f8-ec09873b3929"
   },
   "outputs": [],
   "source": [
    "class AI_detector:\n",
    "    def __init__(self, vocab_size, embedding_dim, seq_length, lr_scheduler, learning_rate):\n",
    "        self.vocab_size = vocab_size+1\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.seq_length = seq_length\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def create(self, n_ff, n_lstm, attention_type, dense_units, hidden_units, dropout, verbose=False):\n",
    "        inputs = Input(shape=(self.seq_length,))\n",
    "        x = Embedding(self.vocab_size, self.embedding_dim, input_length = self.seq_length)(inputs)\n",
    "\n",
    "        for _ in range(n_lstm):\n",
    "            x = LSTM(hidden_units, return_sequences=True, dropout=dropout)(x)\n",
    "\n",
    "        if attention_type == 'soft':\n",
    "            x = SoftAttention()(x)\n",
    "        elif attention_type == 'sdp':\n",
    "            attention = ScaledDotProductAttention()(x,x,x,self.embedding_dim)\n",
    "            x = tf.reduce_sum(attention, axis=1)\n",
    "        else:\n",
    "            if attention_type != None:\n",
    "                print(f\"Attention type {attention_type} not recognized.\")\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        for _ in range(n_ff):\n",
    "            x = Dense(dense_units)(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "        outputs = Dense(2, activation='softmax')(x)\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "        if verbose:\n",
    "            model.summary()\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X_train, y_train, batch_size=32, validation_data=None, model_path=None, save=False, save_best_only=True):\n",
    "        if validation_data != None:\n",
    "            monitor = 'val_loss'\n",
    "        else:\n",
    "            monitor = 'loss'\n",
    "\n",
    "        callbacks = [LearningRateScheduler(self.lr_scheduler), EarlyStopping(monitor=monitor, patience=patience)]\n",
    "\n",
    "        if save:\n",
    "            callbacks.append(ModelCheckpoint(filepath=model_path, monitor=monitor, mode='min', save_best_only=True))\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=self.learning_rate), metrics = ['accuracy'])\n",
    "\n",
    "        if validation_data != None:\n",
    "            return self.model.fit(X_train, y_train, epochs = epochs, validation_data = validation_data, batch_size = batch_size, callbacks = callbacks, verbose = 1)\n",
    "        else:\n",
    "            return self.model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, callbacks = callbacks, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:05.856633Z",
     "iopub.status.busy": "2024-02-05T00:56:05.856341Z",
     "iopub.status.idle": "2024-02-05T00:56:05.865916Z",
     "shell.execute_reply": "2024-02-05T00:56:05.865108Z",
     "shell.execute_reply.started": "2024-02-05T00:56:05.856609Z"
    },
    "id": "978d13ee-21ff-445c-b49c-01a9dd35fe8c"
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch+1 <= warmup:\n",
    "        return learning_rate\n",
    "    return learning_rate*np.power(epoch+1-warmup, decay_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:05.867504Z",
     "iopub.status.busy": "2024-02-05T00:56:05.867204Z",
     "iopub.status.idle": "2024-02-05T00:56:05.876639Z",
     "shell.execute_reply": "2024-02-05T00:56:05.875735Z",
     "shell.execute_reply.started": "2024-02-05T00:56:05.867479Z"
    },
    "id": "729118b0-a230-4daa-aca0-12084cf2ed42"
   },
   "outputs": [],
   "source": [
    "#os.mkdir(\"models\")\n",
    "\n",
    "def get_model_path(embedding_dim, n_ff, n_lstm, attention_type, units, dropout):\n",
    "    return \"models/\"+f\"model_{embedding_dim}_{'FF' if n_lstm==0 else 'LSTM'}_{'' if attention_type == None else attention_type}_{units}_{dropout}\"\n",
    "\n",
    "def train_model(embedding_dim, n_ff, n_lstm, attention_type, units, dropout):\n",
    "    model = AI_detector(vocab_size, embedding_dim, seq_length, lr_scheduler, learning_rate)\n",
    "    model_path = get_model_path(embedding_dim, n_ff, n_lstm, attention_type, units, dropout)\n",
    "    model.create(n_ff, n_lstm, attention_type, units, units, dropout)\n",
    "    print(f\"Built model with embedding_dim = {embedding_dim}, n_ff = {n_ff}, n_lstm = {n_lstm}, attention_type = {attention_type}, units = {units}, dropout = {dropout}\")\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        batch_size=batch_size, save=True,\n",
    "                        model_path=model_path)\n",
    "    print(\"Saved model to \" + model_path)\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T10:41:03.511619Z",
     "iopub.status.busy": "2024-02-04T10:41:03.511341Z",
     "iopub.status.idle": "2024-02-04T10:41:03.524352Z",
     "shell.execute_reply": "2024-02-04T10:41:03.523526Z",
     "shell.execute_reply.started": "2024-02-04T10:41:03.511596Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "patience = 10\n",
    "\n",
    "def train_models_1():\n",
    "    global learning_rate\n",
    "    global warmup\n",
    "    global decay_power\n",
    "    global batch_size\n",
    "    \n",
    "    learning_rate = 1e-4\n",
    "    warmup = 8\n",
    "    decay_power = -0.5\n",
    "    batch_size=64\n",
    "\n",
    "    for FF in [True, False]:\n",
    "        for embedding_dim in [16, 64]:\n",
    "            for units in [16, 64]:\n",
    "                for dropout in [0.2,0.5]:\n",
    "                    train_model(embedding_dim, 1 if FF else 0, 0 if FF else 1, None, units, dropout)\n",
    "    \n",
    "\n",
    "def train_models_2():\n",
    "    global learning_rate\n",
    "    global warmup\n",
    "    global decay_power\n",
    "    global batch_size\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    warmup = 5\n",
    "    decay_power = -0.5\n",
    "    batch_size=32\n",
    "\n",
    "    for embedding_dim in [16, 64]:\n",
    "        for units in [16, 64]:\n",
    "            for dropout in [0.2,0.5]:\n",
    "                train_model(embedding_dim, 1, 0, 'sdp', units, dropout)\n",
    "        \n",
    "def train_models_3():\n",
    "    global learning_rate\n",
    "    global warmup\n",
    "    global decay_power\n",
    "    global batch_size\n",
    "\n",
    "    learning_rate = 5e-4\n",
    "    warmup = 10\n",
    "    decay_power = -0.25\n",
    "    batch_size=32\n",
    "\n",
    "    for embedding_dim in [16, 64]:\n",
    "        for units in [16, 64]:\n",
    "            for dropout in [0.2,0.5]:\n",
    "                train_model(embedding_dim, 1, 0, 'soft', units, dropout)\n",
    "\n",
    "def train_models_4():\n",
    "    global learning_rate\n",
    "    global warmup\n",
    "    global decay_power\n",
    "    global batch_size\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    warmup = 5\n",
    "    decay_power = -0.5\n",
    "    batch_size=32\n",
    "\n",
    "    for dropout in [0.2,0.5]:\n",
    "        train_model(16, 0, 1, 'sdp', 16, dropout)\n",
    "\n",
    "    learning_rate = 5e-4\n",
    "    warmup = 10\n",
    "    decay_power = -0.25\n",
    "    batch_size=32\n",
    "\n",
    "    for dropout in [0.2,0.5]:\n",
    "        train_model(16, 0, 1, 'soft', 16, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T03:20:42.665643Z",
     "iopub.status.busy": "2024-02-04T03:20:42.665362Z",
     "iopub.status.idle": "2024-02-04T04:32:44.017201Z",
     "shell.execute_reply": "2024-02-04T04:32:44.016077Z",
     "shell.execute_reply.started": "2024-02-04T03:20:42.665621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = None, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707016845.698468     230 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 28s 106ms/step - loss: 0.6252 - accuracy: 0.6760 - val_loss: 0.5184 - val_accuracy: 0.8447 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 21s 87ms/step - loss: 0.3252 - accuracy: 0.9246 - val_loss: 0.1807 - val_accuracy: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 18s 72ms/step - loss: 0.1043 - accuracy: 0.9802 - val_loss: 0.0775 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 14s 56ms/step - loss: 0.0473 - accuracy: 0.9914 - val_loss: 0.0487 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 11s 44ms/step - loss: 0.0283 - accuracy: 0.9946 - val_loss: 0.0395 - val_accuracy: 0.9883 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 10s 40ms/step - loss: 0.0191 - accuracy: 0.9961 - val_loss: 0.0336 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 10s 42ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0291 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0282 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0260 - val_accuracy: 0.9917 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 6s 24ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.0253 - val_accuracy: 0.9912 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0263 - val_accuracy: 0.9912 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 5s 21ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0255 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 6s 24ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0251 - val_accuracy: 0.9917 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0248 - val_accuracy: 0.9917 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0250 - val_accuracy: 0.9914 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0249 - val_accuracy: 0.9917 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0244 - val_accuracy: 0.9917 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0250 - val_accuracy: 0.9914 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0240 - val_accuracy: 0.9914 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0248 - val_accuracy: 0.9917 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0242 - val_accuracy: 0.9917 - lr: 2.7735e-05\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0241 - val_accuracy: 0.9919 - lr: 2.6726e-05\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0246 - val_accuracy: 0.9922 - lr: 2.5820e-05\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0244 - val_accuracy: 0.9922 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0246 - val_accuracy: 0.9919 - lr: 2.4254e-05\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0241 - val_accuracy: 0.9925 - lr: 2.3570e-05\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0251 - val_accuracy: 0.9917 - lr: 2.2942e-05\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9925 - lr: 2.2361e-05\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9925 - lr: 2.1822e-05\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0241 - val_accuracy: 0.9927 - lr: 2.1320e-05\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9927 - lr: 2.0851e-05\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0243 - val_accuracy: 0.9927 - lr: 2.0412e-05\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9930 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9922 - lr: 1.9612e-05\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0242 - val_accuracy: 0.9927 - lr: 1.9245e-05\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 3s 10ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0240 - val_accuracy: 0.9927 - lr: 1.8898e-05\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0240 - val_accuracy: 0.9930 - lr: 1.8570e-05\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0241 - val_accuracy: 0.9927 - lr: 1.8257e-05\n",
      "Saved model to models/model_16_FF__16_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = None, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 17s 66ms/step - loss: 0.6337 - accuracy: 0.6484 - val_loss: 0.5203 - val_accuracy: 0.8402 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 13s 51ms/step - loss: 0.3436 - accuracy: 0.9188 - val_loss: 0.1955 - val_accuracy: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 10s 42ms/step - loss: 0.1194 - accuracy: 0.9799 - val_loss: 0.0776 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 9s 36ms/step - loss: 0.0555 - accuracy: 0.9899 - val_loss: 0.0601 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 8s 33ms/step - loss: 0.0330 - accuracy: 0.9935 - val_loss: 0.0375 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 6s 23ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.0386 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.0312 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0297 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.0281 - val_accuracy: 0.9912 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 3s 14ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0293 - val_accuracy: 0.9909 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 5s 22ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0276 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 4s 14ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.0296 - val_accuracy: 0.9904 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.0286 - val_accuracy: 0.9914 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.0281 - val_accuracy: 0.9922 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0290 - val_accuracy: 0.9914 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0283 - val_accuracy: 0.9922 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0289 - val_accuracy: 0.9922 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0284 - val_accuracy: 0.9922 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0282 - val_accuracy: 0.9922 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0292 - val_accuracy: 0.9917 - lr: 2.7735e-05\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 2.6726e-05\n",
      "Saved model to models/model_16_FF__16_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = None, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 16s 64ms/step - loss: 0.5857 - accuracy: 0.6950 - val_loss: 0.3988 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 13s 53ms/step - loss: 0.2087 - accuracy: 0.9555 - val_loss: 0.1113 - val_accuracy: 0.9735 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 10s 41ms/step - loss: 0.0585 - accuracy: 0.9883 - val_loss: 0.0643 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.0529 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 8s 32ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.0460 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0336 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 6s 24ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 0.0306 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 5s 21ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0379 - val_accuracy: 0.9862 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0301 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0297 - val_accuracy: 0.9896 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0289 - val_accuracy: 0.9909 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0295 - val_accuracy: 0.9899 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0304 - val_accuracy: 0.9893 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0300 - val_accuracy: 0.9899 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0289 - val_accuracy: 0.9906 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0294 - val_accuracy: 0.9901 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0294 - val_accuracy: 0.9901 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0289 - val_accuracy: 0.9901 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0291 - val_accuracy: 0.9904 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0293 - val_accuracy: 0.9901 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0291 - val_accuracy: 0.9901 - lr: 2.7735e-05\n",
      "Saved model to models/model_16_FF__64_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = None, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 16s 65ms/step - loss: 0.6082 - accuracy: 0.6773 - val_loss: 0.4675 - val_accuracy: 0.7791 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 13s 52ms/step - loss: 0.2270 - accuracy: 0.9520 - val_loss: 0.1370 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 10s 40ms/step - loss: 0.0612 - accuracy: 0.9892 - val_loss: 0.0532 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0286 - accuracy: 0.9948 - val_loss: 0.0381 - val_accuracy: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 8s 31ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.0330 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 6s 25ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0291 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 5s 22ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0275 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0298 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0282 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 5s 20ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0262 - val_accuracy: 0.9927 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0258 - val_accuracy: 0.9925 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0273 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0274 - val_accuracy: 0.9912 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0257 - val_accuracy: 0.9925 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0259 - val_accuracy: 0.9919 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0258 - val_accuracy: 0.9919 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9925 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9925 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 3s 10ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0255 - val_accuracy: 0.9922 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9925 - lr: 2.7735e-05\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9930 - lr: 2.6726e-05\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9922 - lr: 2.5820e-05\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 2s 7ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0255 - val_accuracy: 0.9919 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 3s 10ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0246 - val_accuracy: 0.9935 - lr: 2.4254e-05\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0257 - val_accuracy: 0.9917 - lr: 2.3570e-05\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 2s 7ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 2.2942e-05\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 2s 7ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9925 - lr: 2.2361e-05\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 2.1822e-05\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 1s 6ms/step - loss: 9.5129e-04 - accuracy: 0.9999 - val_loss: 0.0251 - val_accuracy: 0.9930 - lr: 2.1320e-05\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 9.3452e-04 - accuracy: 0.9999 - val_loss: 0.0246 - val_accuracy: 0.9935 - lr: 2.0851e-05\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 2s 6ms/step - loss: 9.2892e-04 - accuracy: 0.9999 - val_loss: 0.0248 - val_accuracy: 0.9930 - lr: 2.0412e-05\n",
      "Epoch 33/100\n",
      "244/244 [==============================] - 1s 6ms/step - loss: 8.8967e-04 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9930 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 7.5765e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 1.9612e-05\n",
      "Epoch 35/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 6.7722e-04 - accuracy: 0.9999 - val_loss: 0.0258 - val_accuracy: 0.9922 - lr: 1.9245e-05\n",
      "Epoch 36/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 8.1257e-04 - accuracy: 0.9999 - val_loss: 0.0250 - val_accuracy: 0.9930 - lr: 1.8898e-05\n",
      "Epoch 37/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 7.9622e-04 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9930 - lr: 1.8570e-05\n",
      "Epoch 38/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 6.8771e-04 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 1.8257e-05\n",
      "Epoch 39/100\n",
      "244/244 [==============================] - 2s 8ms/step - loss: 8.0270e-04 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9932 - lr: 1.7961e-05\n",
      "Epoch 40/100\n",
      "244/244 [==============================] - 2s 7ms/step - loss: 6.6599e-04 - accuracy: 0.9999 - val_loss: 0.0249 - val_accuracy: 0.9930 - lr: 1.7678e-05\n",
      "Epoch 41/100\n",
      "244/244 [==============================] - 2s 7ms/step - loss: 6.0701e-04 - accuracy: 0.9999 - val_loss: 0.0252 - val_accuracy: 0.9932 - lr: 1.7408e-05\n",
      "Saved model to models/model_16_FF__64_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = None, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 29s 114ms/step - loss: 0.5680 - accuracy: 0.7025 - val_loss: 0.3231 - val_accuracy: 0.8912 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 22s 89ms/step - loss: 0.1462 - accuracy: 0.9680 - val_loss: 0.0799 - val_accuracy: 0.9810 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 0.0428 - accuracy: 0.9924 - val_loss: 0.0477 - val_accuracy: 0.9849 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 16s 64ms/step - loss: 0.0208 - accuracy: 0.9970 - val_loss: 0.0353 - val_accuracy: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 13s 54ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 10s 43ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0284 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 8s 35ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0287 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 9s 38ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0270 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 7s 30ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0267 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0277 - val_accuracy: 0.9906 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 7s 29ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0267 - val_accuracy: 0.9914 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 6s 23ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 5s 20ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0291 - val_accuracy: 0.9901 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0271 - val_accuracy: 0.9917 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 5s 21ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0281 - val_accuracy: 0.9909 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 9.7230e-04 - accuracy: 0.9999 - val_loss: 0.0276 - val_accuracy: 0.9912 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 8.5041e-04 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9919 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 8.5439e-04 - accuracy: 0.9999 - val_loss: 0.0280 - val_accuracy: 0.9917 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 6.9922e-04 - accuracy: 0.9999 - val_loss: 0.0282 - val_accuracy: 0.9912 - lr: 3.0151e-05\n",
      "Saved model to models/model_64_FF__16_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = None, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.6185 - accuracy: 0.6719 - val_loss: 0.3633 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 14s 58ms/step - loss: 0.1737 - accuracy: 0.9630 - val_loss: 0.0835 - val_accuracy: 0.9810 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 11s 43ms/step - loss: 0.0503 - accuracy: 0.9919 - val_loss: 0.0472 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 9s 35ms/step - loss: 0.0242 - accuracy: 0.9967 - val_loss: 0.0368 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 9s 35ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 0.0341 - val_accuracy: 0.9886 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 8s 33ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0317 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 7s 29ms/step - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.0313 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0285 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 5s 20ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0296 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 5s 21ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0288 - val_accuracy: 0.9912 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0302 - val_accuracy: 0.9906 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0297 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0305 - val_accuracy: 0.9912 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0303 - val_accuracy: 0.9909 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0301 - val_accuracy: 0.9912 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 14ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0301 - val_accuracy: 0.9912 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0305 - val_accuracy: 0.9909 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0308 - val_accuracy: 0.9909 - lr: 3.1623e-05\n",
      "Saved model to models/model_64_FF__16_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = None, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.5533 - accuracy: 0.7143 - val_loss: 0.2228 - val_accuracy: 0.9454 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 13s 54ms/step - loss: 0.0980 - accuracy: 0.9799 - val_loss: 0.0651 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 11s 47ms/step - loss: 0.0285 - accuracy: 0.9946 - val_loss: 0.0376 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 10s 41ms/step - loss: 0.0134 - accuracy: 0.9981 - val_loss: 0.0309 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 9s 37ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.0282 - val_accuracy: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 7s 30ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0268 - val_accuracy: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 6s 24ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0292 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0255 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 5s 20ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0293 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 9.5057e-04 - accuracy: 0.9999 - val_loss: 0.0267 - val_accuracy: 0.9922 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 8.3968e-04 - accuracy: 0.9999 - val_loss: 0.0270 - val_accuracy: 0.9917 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 7.8220e-04 - accuracy: 0.9999 - val_loss: 0.0268 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 6.8505e-04 - accuracy: 0.9999 - val_loss: 0.0265 - val_accuracy: 0.9930 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 5.9381e-04 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9922 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 6.1036e-04 - accuracy: 0.9999 - val_loss: 0.0265 - val_accuracy: 0.9927 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 14ms/step - loss: 5.3792e-04 - accuracy: 0.9999 - val_loss: 0.0267 - val_accuracy: 0.9927 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 5.4582e-04 - accuracy: 0.9999 - val_loss: 0.0264 - val_accuracy: 0.9932 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 5.3037e-04 - accuracy: 0.9999 - val_loss: 0.0269 - val_accuracy: 0.9927 - lr: 3.1623e-05\n",
      "Saved model to models/model_64_FF__64_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = None, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 17s 66ms/step - loss: 0.6299 - accuracy: 0.6759 - val_loss: 0.3145 - val_accuracy: 0.8852 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 14s 56ms/step - loss: 0.1356 - accuracy: 0.9684 - val_loss: 0.0694 - val_accuracy: 0.9813 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 12s 49ms/step - loss: 0.0349 - accuracy: 0.9940 - val_loss: 0.0406 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 10s 41ms/step - loss: 0.0160 - accuracy: 0.9978 - val_loss: 0.0377 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 9s 35ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0280 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 7s 29ms/step - loss: 0.0056 - accuracy: 0.9994 - val_loss: 0.0273 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 6s 25ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0274 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 6s 25ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0270 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 5s 20ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0284 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 4s 17ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9909 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 5s 19ms/step - loss: 9.8723e-04 - accuracy: 0.9999 - val_loss: 0.0283 - val_accuracy: 0.9912 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 4s 18ms/step - loss: 9.3365e-04 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 4s 15ms/step - loss: 8.0950e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9906 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 8.2472e-04 - accuracy: 0.9999 - val_loss: 0.0278 - val_accuracy: 0.9909 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 7.5871e-04 - accuracy: 0.9999 - val_loss: 0.0271 - val_accuracy: 0.9909 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 6.8538e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9906 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 6.8268e-04 - accuracy: 0.9999 - val_loss: 0.0269 - val_accuracy: 0.9914 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 3s 12ms/step - loss: 6.3506e-04 - accuracy: 0.9999 - val_loss: 0.0279 - val_accuracy: 0.9909 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 6.0119e-04 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9917 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 4s 16ms/step - loss: 5.6486e-04 - accuracy: 0.9999 - val_loss: 0.0269 - val_accuracy: 0.9917 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 4.8681e-04 - accuracy: 0.9999 - val_loss: 0.0276 - val_accuracy: 0.9912 - lr: 2.7735e-05\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 3s 13ms/step - loss: 5.6760e-04 - accuracy: 0.9999 - val_loss: 0.0268 - val_accuracy: 0.9917 - lr: 2.6726e-05\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 4.8048e-04 - accuracy: 0.9999 - val_loss: 0.0280 - val_accuracy: 0.9912 - lr: 2.5820e-05\n",
      "Epoch 24/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 4.9556e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9914 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 5.1754e-04 - accuracy: 0.9999 - val_loss: 0.0272 - val_accuracy: 0.9914 - lr: 2.4254e-05\n",
      "Epoch 26/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 5.0015e-04 - accuracy: 0.9999 - val_loss: 0.0279 - val_accuracy: 0.9912 - lr: 2.3570e-05\n",
      "Epoch 27/100\n",
      "244/244 [==============================] - 2s 10ms/step - loss: 4.2665e-04 - accuracy: 0.9999 - val_loss: 0.0279 - val_accuracy: 0.9914 - lr: 2.2942e-05\n",
      "Epoch 28/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 4.6459e-04 - accuracy: 0.9999 - val_loss: 0.0280 - val_accuracy: 0.9912 - lr: 2.2361e-05\n",
      "Epoch 29/100\n",
      "244/244 [==============================] - 2s 9ms/step - loss: 5.1583e-04 - accuracy: 0.9999 - val_loss: 0.0280 - val_accuracy: 0.9912 - lr: 2.1822e-05\n",
      "Epoch 30/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 4.1665e-04 - accuracy: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9917 - lr: 2.1320e-05\n",
      "Epoch 31/100\n",
      "244/244 [==============================] - 3s 10ms/step - loss: 4.2137e-04 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9917 - lr: 2.0851e-05\n",
      "Epoch 32/100\n",
      "244/244 [==============================] - 3s 11ms/step - loss: 4.2890e-04 - accuracy: 0.9999 - val_loss: 0.0274 - val_accuracy: 0.9917 - lr: 2.0412e-05\n",
      "Saved model to models/model_64_FF__64_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = None, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 35s 132ms/step - loss: 0.6202 - accuracy: 0.6894 - val_loss: 0.4275 - val_accuracy: 0.8912 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 28s 114ms/step - loss: 0.1539 - accuracy: 0.9630 - val_loss: 0.0881 - val_accuracy: 0.9698 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 26s 106ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0603 - val_accuracy: 0.9810 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 23s 95ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0536 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0575 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 22s 91ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0462 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 22s 90ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.0455 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 20s 83ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0425 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0566 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0495 - val_accuracy: 0.9886 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0565 - val_accuracy: 0.9870 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 16s 65ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0657 - val_accuracy: 0.9865 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 16s 64ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0602 - val_accuracy: 0.9886 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 15s 63ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0545 - val_accuracy: 0.9893 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 15s 62ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0504 - val_accuracy: 0.9896 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 15s 64ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0524 - val_accuracy: 0.9893 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 16s 64ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0658 - val_accuracy: 0.9870 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 16s 64ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0570 - val_accuracy: 0.9896 - lr: 3.1623e-05\n",
      "Saved model to models/model_16_LSTM__16_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = None, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 33s 130ms/step - loss: 0.6426 - accuracy: 0.6724 - val_loss: 0.5256 - val_accuracy: 0.8028 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 28s 116ms/step - loss: 0.2691 - accuracy: 0.9317 - val_loss: 0.0882 - val_accuracy: 0.9696 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 26s 108ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0529 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 25s 102ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.0447 - val_accuracy: 0.9846 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 23s 94ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0400 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 23s 94ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0354 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 22s 90ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0304 - val_accuracy: 0.9930 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0333 - val_accuracy: 0.9925 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0357 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0328 - val_accuracy: 0.9906 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0351 - val_accuracy: 0.9899 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 16s 65ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0340 - val_accuracy: 0.9909 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0321 - val_accuracy: 0.9914 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 16s 63ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0310 - val_accuracy: 0.9919 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 15s 62ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0346 - val_accuracy: 0.9909 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0311 - val_accuracy: 0.9938 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0329 - val_accuracy: 0.9925 - lr: 3.3333e-05\n",
      "Saved model to models/model_16_LSTM__16_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = None, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 33s 130ms/step - loss: 0.5054 - accuracy: 0.7337 - val_loss: 0.1282 - val_accuracy: 0.9511 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 30s 121ms/step - loss: 0.0631 - accuracy: 0.9792 - val_loss: 0.0573 - val_accuracy: 0.9823 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 27s 109ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.0360 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 26s 106ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0308 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 21s 86ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0375 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 23s 95ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0238 - val_accuracy: 0.9943 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.0306 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.1495 - val_accuracy: 0.9568 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 18s 75ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0426 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0336 - val_accuracy: 0.9938 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0346 - val_accuracy: 0.9922 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0305 - val_accuracy: 0.9948 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0307 - val_accuracy: 0.9943 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0377 - val_accuracy: 0.9919 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0386 - val_accuracy: 0.9945 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0386 - val_accuracy: 0.9935 - lr: 3.5355e-05\n",
      "Saved model to models/model_16_LSTM__64_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = None, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 34s 131ms/step - loss: 0.6241 - accuracy: 0.6442 - val_loss: 0.3556 - val_accuracy: 0.8878 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 29s 118ms/step - loss: 0.1108 - accuracy: 0.9579 - val_loss: 0.1437 - val_accuracy: 0.9443 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 27s 111ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0555 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 25s 103ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.0379 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 24s 98ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0356 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 23s 95ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0309 - val_accuracy: 0.9917 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 19s 80ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0330 - val_accuracy: 0.9919 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 23s 92ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0280 - val_accuracy: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 21s 87ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0271 - val_accuracy: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0349 - val_accuracy: 0.9891 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0335 - val_accuracy: 0.9896 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0320 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 16s 68ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0298 - val_accuracy: 0.9938 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0295 - val_accuracy: 0.9922 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0278 - val_accuracy: 0.9932 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0450 - val_accuracy: 0.9909 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 16s 68ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0396 - val_accuracy: 0.9896 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0325 - val_accuracy: 0.9927 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0440 - val_accuracy: 0.9906 - lr: 3.0151e-05\n",
      "Saved model to models/model_16_LSTM__64_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 0, n_lstm = 1, attention_type = None, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 34s 130ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.0724 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 29s 120ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 0.0399 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 27s 111ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0291 - val_accuracy: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 22s 92ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0295 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 20s 82ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0299 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 19s 79ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0333 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0298 - val_accuracy: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0334 - val_accuracy: 0.9919 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0398 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0340 - val_accuracy: 0.9919 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0365 - val_accuracy: 0.9925 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0440 - val_accuracy: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0426 - val_accuracy: 0.9919 - lr: 4.4721e-05\n",
      "Saved model to models/model_64_LSTM__16_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 0, n_lstm = 1, attention_type = None, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 34s 132ms/step - loss: 0.4843 - accuracy: 0.8034 - val_loss: 0.1512 - val_accuracy: 0.9641 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 28s 116ms/step - loss: 0.0622 - accuracy: 0.9831 - val_loss: 0.0600 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 27s 108ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0338 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 21s 88ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0350 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 21s 85ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0360 - val_accuracy: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0445 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 19s 77ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0478 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0443 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 21s 87ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0302 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0333 - val_accuracy: 0.9919 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 20s 83ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0288 - val_accuracy: 0.9922 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0395 - val_accuracy: 0.9904 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0317 - val_accuracy: 0.9919 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0319 - val_accuracy: 0.9927 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0344 - val_accuracy: 0.9925 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 16s 67ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0314 - val_accuracy: 0.9932 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 15s 63ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0403 - val_accuracy: 0.9914 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0407 - val_accuracy: 0.9912 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0343 - val_accuracy: 0.9930 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0311 - val_accuracy: 0.9932 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 16s 65ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0355 - val_accuracy: 0.9919 - lr: 2.7735e-05\n",
      "Saved model to models/model_64_LSTM__16_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 0, n_lstm = 1, attention_type = None, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 35s 136ms/step - loss: 0.3433 - accuracy: 0.8317 - val_loss: 0.0631 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 30s 123ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0350 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 28s 113ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.0297 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 22s 90ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0328 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 21s 85ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0314 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 21s 86ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0427 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 20s 81ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0429 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 23s 93ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0245 - val_accuracy: 0.9943 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 19s 76ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0308 - val_accuracy: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0292 - val_accuracy: 0.9956 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0402 - val_accuracy: 0.9945 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 18s 73ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0275 - val_accuracy: 0.9951 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 20s 83ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0240 - val_accuracy: 0.9948 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9940 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0290 - val_accuracy: 0.9945 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 5.0835e-04 - accuracy: 0.9998 - val_loss: 0.0448 - val_accuracy: 0.9940 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 4.6536e-04 - accuracy: 0.9999 - val_loss: 0.0402 - val_accuracy: 0.9943 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 5.9201e-04 - accuracy: 0.9997 - val_loss: 0.0356 - val_accuracy: 0.9958 - lr: 3.1623e-05\n",
      "Epoch 19/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 2.8020e-04 - accuracy: 0.9999 - val_loss: 0.0466 - val_accuracy: 0.9938 - lr: 3.0151e-05\n",
      "Epoch 20/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 2.7538e-04 - accuracy: 0.9999 - val_loss: 0.0460 - val_accuracy: 0.9940 - lr: 2.8868e-05\n",
      "Epoch 21/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 4.9890e-04 - accuracy: 0.9998 - val_loss: 0.0329 - val_accuracy: 0.9951 - lr: 2.7735e-05\n",
      "Epoch 22/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 2.2545e-04 - accuracy: 0.9999 - val_loss: 0.0490 - val_accuracy: 0.9932 - lr: 2.6726e-05\n",
      "Epoch 23/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 2.2643e-04 - accuracy: 0.9999 - val_loss: 0.0585 - val_accuracy: 0.9927 - lr: 2.5820e-05\n",
      "Saved model to models/model_64_LSTM__64_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 0, n_lstm = 1, attention_type = None, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "244/244 [==============================] - 35s 138ms/step - loss: 0.3518 - accuracy: 0.8223 - val_loss: 0.0748 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "244/244 [==============================] - 28s 117ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.0695 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "244/244 [==============================] - 27s 112ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.0304 - val_accuracy: 0.9886 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "244/244 [==============================] - 23s 92ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0400 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "244/244 [==============================] - 25s 102ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0287 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "244/244 [==============================] - 24s 99ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0276 - val_accuracy: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "244/244 [==============================] - 23s 94ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0276 - val_accuracy: 0.9940 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "244/244 [==============================] - 22s 91ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0207 - val_accuracy: 0.9943 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "244/244 [==============================] - 19s 78ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0229 - val_accuracy: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "244/244 [==============================] - 18s 75ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0368 - val_accuracy: 0.9922 - lr: 7.0711e-05\n",
      "Epoch 11/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0314 - val_accuracy: 0.9925 - lr: 5.7735e-05\n",
      "Epoch 12/100\n",
      "244/244 [==============================] - 18s 74ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0308 - val_accuracy: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "244/244 [==============================] - 18s 72ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0407 - val_accuracy: 0.9909 - lr: 4.4721e-05\n",
      "Epoch 14/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0236 - val_accuracy: 0.9951 - lr: 4.0825e-05\n",
      "Epoch 15/100\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0269 - val_accuracy: 0.9935 - lr: 3.7796e-05\n",
      "Epoch 16/100\n",
      "244/244 [==============================] - 17s 71ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0324 - val_accuracy: 0.9927 - lr: 3.5355e-05\n",
      "Epoch 17/100\n",
      "244/244 [==============================] - 17s 70ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0247 - val_accuracy: 0.9948 - lr: 3.3333e-05\n",
      "Epoch 18/100\n",
      "244/244 [==============================] - 17s 69ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0250 - val_accuracy: 0.9945 - lr: 3.1623e-05\n",
      "Saved model to models/model_64_LSTM__64_0.5\n"
     ]
    }
   ],
   "source": [
    "train_models_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T04:41:25.056722Z",
     "iopub.status.busy": "2024-02-04T04:41:25.055917Z",
     "iopub.status.idle": "2024-02-04T06:55:05.830817Z",
     "shell.execute_reply": "2024-02-04T06:55:05.829948Z",
     "shell.execute_reply.started": "2024-02-04T04:41:25.056692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707021688.098786     108 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 65s 127ms/step - loss: 10.5322 - accuracy: 0.5889 - val_loss: 0.1893 - val_accuracy: 0.9217 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 50s 102ms/step - loss: 0.2986 - accuracy: 0.9124 - val_loss: 0.0694 - val_accuracy: 0.9753 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 44s 90ms/step - loss: 0.0679 - accuracy: 0.9777 - val_loss: 0.0437 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 40s 82ms/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0338 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 39s 81ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0319 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.0315 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.0356 - val_accuracy: 0.9896 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0282 - val_accuracy: 0.9925 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.0271 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 35s 71ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0275 - val_accuracy: 0.9932 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.0281 - val_accuracy: 0.9930 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0276 - val_accuracy: 0.9932 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0315 - val_accuracy: 0.9927 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0283 - val_accuracy: 0.9935 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0284 - val_accuracy: 0.9935 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.0297 - val_accuracy: 0.9938 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 33s 69ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.0273 - val_accuracy: 0.9930 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0272 - val_accuracy: 0.9932 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.0299 - val_accuracy: 0.9938 - lr: 2.6726e-05\n",
      "Saved model to models/model_16_FF_sdp_16_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 43s 86ms/step - loss: 3.5741 - accuracy: 0.6984 - val_loss: 0.0664 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 39s 79ms/step - loss: 0.1392 - accuracy: 0.9476 - val_loss: 0.0456 - val_accuracy: 0.9846 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0602 - accuracy: 0.9792 - val_loss: 0.0491 - val_accuracy: 0.9831 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0438 - accuracy: 0.9866 - val_loss: 0.0346 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0361 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0403 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 0.0489 - val_accuracy: 0.9870 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.0336 - val_accuracy: 0.9925 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0172 - accuracy: 0.9970 - val_loss: 0.0351 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0379 - val_accuracy: 0.9914 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0342 - val_accuracy: 0.9927 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0322 - val_accuracy: 0.9930 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.0320 - val_accuracy: 0.9932 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0332 - val_accuracy: 0.9935 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0367 - val_accuracy: 0.9925 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.0417 - val_accuracy: 0.9912 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0324 - val_accuracy: 0.9935 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0345 - val_accuracy: 0.9932 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.0402 - val_accuracy: 0.9917 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0317 - val_accuracy: 0.9938 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0110 - accuracy: 0.9987 - val_loss: 0.0333 - val_accuracy: 0.9940 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0319 - val_accuracy: 0.9938 - lr: 2.4254e-05\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0324 - val_accuracy: 0.9940 - lr: 2.3570e-05\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0346 - val_accuracy: 0.9935 - lr: 2.2942e-05\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.0363 - val_accuracy: 0.9930 - lr: 2.2361e-05\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0333 - val_accuracy: 0.9940 - lr: 2.1822e-05\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.0346 - val_accuracy: 0.9935 - lr: 2.1320e-05\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.0350 - val_accuracy: 0.9935 - lr: 2.0851e-05\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0345 - val_accuracy: 0.9935 - lr: 2.0412e-05\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0403 - val_accuracy: 0.9925 - lr: 2.0000e-05\n",
      "Saved model to models/model_16_FF_sdp_16_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 43s 86ms/step - loss: 4.0451 - accuracy: 0.6241 - val_loss: 0.1122 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 38s 79ms/step - loss: 0.3379 - accuracy: 0.9206 - val_loss: 0.0689 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0682 - accuracy: 0.9802 - val_loss: 0.0642 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.0544 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 34s 71ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.0561 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.0491 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.0628 - val_accuracy: 0.9872 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0467 - val_accuracy: 0.9912 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0113 - accuracy: 0.9982 - val_loss: 0.0482 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.0489 - val_accuracy: 0.9906 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0442 - val_accuracy: 0.9917 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 0.0470 - val_accuracy: 0.9917 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0502 - val_accuracy: 0.9901 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0427 - val_accuracy: 0.9917 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.0669 - val_accuracy: 0.9872 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0549 - val_accuracy: 0.9901 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.0508 - val_accuracy: 0.9909 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0505 - val_accuracy: 0.9906 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0485 - val_accuracy: 0.9917 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0453 - val_accuracy: 0.9917 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0419 - val_accuracy: 0.9922 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0430 - val_accuracy: 0.9917 - lr: 2.4254e-05\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0498 - val_accuracy: 0.9917 - lr: 2.3570e-05\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0475 - val_accuracy: 0.9919 - lr: 2.2942e-05\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0459 - val_accuracy: 0.9919 - lr: 2.2361e-05\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0493 - val_accuracy: 0.9917 - lr: 2.1822e-05\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0542 - val_accuracy: 0.9899 - lr: 2.1320e-05\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0434 - val_accuracy: 0.9919 - lr: 2.0851e-05\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0471 - val_accuracy: 0.9919 - lr: 2.0412e-05\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0451 - val_accuracy: 0.9927 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0501 - val_accuracy: 0.9917 - lr: 1.9612e-05\n",
      "Saved model to models/model_16_FF_sdp_64_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 43s 87ms/step - loss: 11.1701 - accuracy: 0.5996 - val_loss: 0.1137 - val_accuracy: 0.9615 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 38s 79ms/step - loss: 0.4807 - accuracy: 0.9148 - val_loss: 0.0851 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0844 - accuracy: 0.9791 - val_loss: 0.0754 - val_accuracy: 0.9828 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0430 - accuracy: 0.9885 - val_loss: 0.0547 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 34s 71ms/step - loss: 0.0276 - accuracy: 0.9934 - val_loss: 0.0463 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 0.0458 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.0477 - val_accuracy: 0.9896 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 34s 69ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.0395 - val_accuracy: 0.9919 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.0400 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0383 - val_accuracy: 0.9930 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0463 - val_accuracy: 0.9899 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0375 - val_accuracy: 0.9930 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.0462 - val_accuracy: 0.9899 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.0427 - val_accuracy: 0.9917 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0378 - val_accuracy: 0.9927 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0384 - val_accuracy: 0.9930 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.0382 - val_accuracy: 0.9930 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.0406 - val_accuracy: 0.9927 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0462 - val_accuracy: 0.9914 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0415 - val_accuracy: 0.9922 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 32s 67ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0400 - val_accuracy: 0.9927 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 33s 67ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.0414 - val_accuracy: 0.9919 - lr: 2.4254e-05\n",
      "Saved model to models/model_16_FF_sdp_64_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 64s 129ms/step - loss: 6.8176 - accuracy: 0.8115 - val_loss: 0.1339 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 51s 104ms/step - loss: 0.0545 - accuracy: 0.9825 - val_loss: 0.4858 - val_accuracy: 0.8894 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 48s 99ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0371 - val_accuracy: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 43s 88ms/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.0635 - val_accuracy: 0.9831 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 41s 85ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0311 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 40s 83ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.0308 - val_accuracy: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 39s 80ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.0310 - val_accuracy: 0.9943 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 39s 79ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0301 - val_accuracy: 0.9935 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 38s 78ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0391 - val_accuracy: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0357 - val_accuracy: 0.9935 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0321 - val_accuracy: 0.9940 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0301 - val_accuracy: 0.9940 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0307 - val_accuracy: 0.9940 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0302 - val_accuracy: 0.9943 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0330 - val_accuracy: 0.9938 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0401 - val_accuracy: 0.9917 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0316 - val_accuracy: 0.9943 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0303 - val_accuracy: 0.9938 - lr: 2.7735e-05\n",
      "Saved model to models/model_64_FF_sdp_16_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 45s 91ms/step - loss: 7.5024 - accuracy: 0.7448 - val_loss: 0.2221 - val_accuracy: 0.9282 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 41s 84ms/step - loss: 0.0806 - accuracy: 0.9754 - val_loss: 0.0522 - val_accuracy: 0.9820 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 39s 80ms/step - loss: 0.0473 - accuracy: 0.9877 - val_loss: 0.0355 - val_accuracy: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 38s 78ms/step - loss: 0.0332 - accuracy: 0.9907 - val_loss: 0.0457 - val_accuracy: 0.9862 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0254 - accuracy: 0.9935 - val_loss: 0.0271 - val_accuracy: 0.9943 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0224 - accuracy: 0.9949 - val_loss: 0.0399 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0331 - val_accuracy: 0.9912 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0269 - val_accuracy: 0.9940 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0119 - accuracy: 0.9981 - val_loss: 0.0445 - val_accuracy: 0.9888 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0279 - val_accuracy: 0.9927 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9930 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0103 - accuracy: 0.9984 - val_loss: 0.0280 - val_accuracy: 0.9938 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0277 - val_accuracy: 0.9945 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0306 - val_accuracy: 0.9932 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.0299 - val_accuracy: 0.9935 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0300 - val_accuracy: 0.9935 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.0277 - val_accuracy: 0.9935 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0283 - val_accuracy: 0.9935 - lr: 2.7735e-05\n",
      "Saved model to models/model_64_FF_sdp_16_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 45s 90ms/step - loss: 4.1374 - accuracy: 0.7433 - val_loss: 0.0931 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 40s 82ms/step - loss: 0.1071 - accuracy: 0.9727 - val_loss: 0.1695 - val_accuracy: 0.9594 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 40s 81ms/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 0.0432 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 38s 79ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.0423 - val_accuracy: 0.9917 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0229 - accuracy: 0.9945 - val_loss: 0.0343 - val_accuracy: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.0646 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.0437 - val_accuracy: 0.9891 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0602 - val_accuracy: 0.9875 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0435 - val_accuracy: 0.9896 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0418 - val_accuracy: 0.9901 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.0342 - val_accuracy: 0.9932 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0407 - val_accuracy: 0.9904 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.0397 - val_accuracy: 0.9914 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.0442 - val_accuracy: 0.9896 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0427 - val_accuracy: 0.9901 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0495 - val_accuracy: 0.9896 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0364 - val_accuracy: 0.9932 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0463 - val_accuracy: 0.9899 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0371 - val_accuracy: 0.9927 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0454 - val_accuracy: 0.9899 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0429 - val_accuracy: 0.9901 - lr: 2.5000e-05\n",
      "Saved model to models/model_64_FF_sdp_64_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = sdp, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 45s 91ms/step - loss: 11.3879 - accuracy: 0.6864 - val_loss: 0.1537 - val_accuracy: 0.9649 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 41s 84ms/step - loss: 0.1504 - accuracy: 0.9674 - val_loss: 0.0673 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 39s 81ms/step - loss: 0.0710 - accuracy: 0.9850 - val_loss: 0.0597 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0496 - accuracy: 0.9877 - val_loss: 0.2443 - val_accuracy: 0.9495 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 38s 77ms/step - loss: 0.0383 - accuracy: 0.9917 - val_loss: 0.0536 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 37s 77ms/step - loss: 0.0357 - accuracy: 0.9917 - val_loss: 0.0479 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 0.0530 - val_accuracy: 0.9917 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0174 - accuracy: 0.9967 - val_loss: 0.0453 - val_accuracy: 0.9919 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0425 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0125 - accuracy: 0.9973 - val_loss: 0.0430 - val_accuracy: 0.9919 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0392 - val_accuracy: 0.9938 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0395 - val_accuracy: 0.9925 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 37s 76ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0384 - val_accuracy: 0.9930 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0444 - val_accuracy: 0.9922 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0405 - val_accuracy: 0.9932 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0393 - val_accuracy: 0.9940 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0390 - val_accuracy: 0.9927 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0380 - val_accuracy: 0.9935 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0381 - val_accuracy: 0.9940 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0430 - val_accuracy: 0.9922 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0378 - val_accuracy: 0.9940 - lr: 2.4254e-05\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0372 - val_accuracy: 0.9935 - lr: 2.3570e-05\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0371 - val_accuracy: 0.9943 - lr: 2.2942e-05\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0362 - val_accuracy: 0.9940 - lr: 2.2361e-05\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0363 - val_accuracy: 0.9940 - lr: 2.1822e-05\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0363 - val_accuracy: 0.9940 - lr: 2.1320e-05\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0367 - val_accuracy: 0.9943 - lr: 2.0851e-05\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0372 - val_accuracy: 0.9943 - lr: 2.0412e-05\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0361 - val_accuracy: 0.9940 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0380 - val_accuracy: 0.9938 - lr: 1.9612e-05\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0398 - val_accuracy: 0.9938 - lr: 1.9245e-05\n",
      "Epoch 33/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.0370 - val_accuracy: 0.9935 - lr: 1.8898e-05\n",
      "Epoch 34/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0365 - val_accuracy: 0.9935 - lr: 1.8570e-05\n",
      "Epoch 35/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0365 - val_accuracy: 0.9935 - lr: 1.8257e-05\n",
      "Epoch 36/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0357 - val_accuracy: 0.9940 - lr: 1.7961e-05\n",
      "Epoch 37/100\n",
      "488/488 [==============================] - 37s 75ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0354 - val_accuracy: 0.9940 - lr: 1.7678e-05\n",
      "Epoch 38/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0361 - val_accuracy: 0.9943 - lr: 1.7408e-05\n",
      "Epoch 39/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0353 - val_accuracy: 0.9940 - lr: 1.7150e-05\n",
      "Epoch 40/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0361 - val_accuracy: 0.9940 - lr: 1.6903e-05\n",
      "Epoch 41/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0369 - val_accuracy: 0.9940 - lr: 1.6667e-05\n",
      "Epoch 42/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0355 - val_accuracy: 0.9938 - lr: 1.6440e-05\n",
      "Epoch 43/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0351 - val_accuracy: 0.9940 - lr: 1.6222e-05\n",
      "Epoch 44/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0358 - val_accuracy: 0.9940 - lr: 1.6013e-05\n",
      "Epoch 45/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0373 - val_accuracy: 0.9940 - lr: 1.5811e-05\n",
      "Epoch 46/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0379 - val_accuracy: 0.9943 - lr: 1.5617e-05\n",
      "Epoch 47/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0389 - val_accuracy: 0.9940 - lr: 1.5430e-05\n",
      "Epoch 48/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0351 - val_accuracy: 0.9940 - lr: 1.5250e-05\n",
      "Epoch 49/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0353 - val_accuracy: 0.9940 - lr: 1.5076e-05\n",
      "Epoch 50/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0350 - val_accuracy: 0.9938 - lr: 1.4907e-05\n",
      "Epoch 51/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9943 - lr: 1.4744e-05\n",
      "Epoch 52/100\n",
      "488/488 [==============================] - 36s 75ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0349 - val_accuracy: 0.9945 - lr: 1.4586e-05\n",
      "Epoch 53/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0363 - val_accuracy: 0.9940 - lr: 1.4434e-05\n",
      "Epoch 54/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0352 - val_accuracy: 0.9943 - lr: 1.4286e-05\n",
      "Epoch 55/100\n",
      "488/488 [==============================] - 36s 74ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0353 - val_accuracy: 0.9943 - lr: 1.4142e-05\n",
      "Epoch 56/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0355 - val_accuracy: 0.9940 - lr: 1.4003e-05\n",
      "Epoch 57/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0359 - val_accuracy: 0.9940 - lr: 1.3868e-05\n",
      "Epoch 58/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0358 - val_accuracy: 0.9940 - lr: 1.3736e-05\n",
      "Epoch 59/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0355 - val_accuracy: 0.9943 - lr: 1.3608e-05\n",
      "Epoch 60/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0352 - val_accuracy: 0.9940 - lr: 1.3484e-05\n",
      "Epoch 61/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 7.7702e-04 - accuracy: 0.9997 - val_loss: 0.0355 - val_accuracy: 0.9943 - lr: 1.3363e-05\n",
      "Epoch 62/100\n",
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0351 - val_accuracy: 0.9943 - lr: 1.3245e-05\n",
      "Saved model to models/model_64_FF_sdp_64_0.5\n"
     ]
    }
   ],
   "source": [
    "train_models_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T07:03:16.327486Z",
     "iopub.status.busy": "2024-02-04T07:03:16.327210Z",
     "iopub.status.idle": "2024-02-04T07:30:04.751406Z",
     "shell.execute_reply": "2024-02-04T07:30:04.750509Z",
     "shell.execute_reply.started": "2024-02-04T07:03:16.327455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = soft, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707030199.313542     106 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 49s 94ms/step - loss: 0.6892 - accuracy: 0.5523 - val_loss: 0.6793 - val_accuracy: 0.7328 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 31s 64ms/step - loss: 0.6338 - accuracy: 0.7576 - val_loss: 0.5502 - val_accuracy: 0.8623 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 19s 40ms/step - loss: 0.3766 - accuracy: 0.9191 - val_loss: 0.2014 - val_accuracy: 0.9638 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 16s 32ms/step - loss: 0.1153 - accuracy: 0.9773 - val_loss: 0.0745 - val_accuracy: 0.9776 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 11s 22ms/step - loss: 0.0568 - accuracy: 0.9851 - val_loss: 0.0572 - val_accuracy: 0.9802 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 10s 20ms/step - loss: 0.0415 - accuracy: 0.9883 - val_loss: 0.0530 - val_accuracy: 0.9820 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 8s 16ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0431 - val_accuracy: 0.9854 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 7s 15ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0424 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.0370 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0357 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0393 - val_accuracy: 0.9891 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0335 - val_accuracy: 0.9893 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 6s 11ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0334 - val_accuracy: 0.9896 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0361 - val_accuracy: 0.9896 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0337 - val_accuracy: 0.9904 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.0313 - val_accuracy: 0.9906 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0327 - val_accuracy: 0.9904 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0308 - val_accuracy: 0.9904 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0329 - val_accuracy: 0.9904 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0330 - val_accuracy: 0.9904 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0305 - val_accuracy: 0.9914 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0316 - val_accuracy: 0.9909 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0307 - val_accuracy: 0.9914 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0292 - val_accuracy: 0.9919 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0299 - val_accuracy: 0.9917 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0309 - val_accuracy: 0.9912 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0299 - val_accuracy: 0.9917 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0310 - val_accuracy: 0.9914 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0309 - val_accuracy: 0.9914 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0295 - val_accuracy: 0.9922 - lr: 2.3644e-04\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0294 - val_accuracy: 0.9919 - lr: 2.3357e-04\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0308 - val_accuracy: 0.9919 - lr: 2.3087e-04\n",
      "Epoch 33/100\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0307 - val_accuracy: 0.9917 - lr: 2.2832e-04\n",
      "Epoch 34/100\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0372 - val_accuracy: 0.9912 - lr: 2.2590e-04\n",
      "Saved model to models/model_16_FF_soft_16_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = soft, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 27s 54ms/step - loss: 0.6895 - accuracy: 0.5538 - val_loss: 0.6820 - val_accuracy: 0.5225 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 17s 36ms/step - loss: 0.6507 - accuracy: 0.7288 - val_loss: 0.5934 - val_accuracy: 0.8361 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 12s 25ms/step - loss: 0.4547 - accuracy: 0.8891 - val_loss: 0.2803 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 10s 20ms/step - loss: 0.1686 - accuracy: 0.9680 - val_loss: 0.0882 - val_accuracy: 0.9750 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 8s 16ms/step - loss: 0.0735 - accuracy: 0.9826 - val_loss: 0.0615 - val_accuracy: 0.9794 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 0.0530 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0394 - accuracy: 0.9894 - val_loss: 0.0454 - val_accuracy: 0.9849 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 6s 11ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0433 - val_accuracy: 0.9854 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0255 - accuracy: 0.9932 - val_loss: 0.0388 - val_accuracy: 0.9872 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.0369 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0356 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.0404 - val_accuracy: 0.9893 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 0.0356 - val_accuracy: 0.9899 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0357 - val_accuracy: 0.9899 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0361 - val_accuracy: 0.9901 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0363 - val_accuracy: 0.9901 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0345 - val_accuracy: 0.9906 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.0345 - val_accuracy: 0.9912 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0331 - val_accuracy: 0.9909 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0345 - val_accuracy: 0.9906 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0359 - val_accuracy: 0.9906 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0330 - val_accuracy: 0.9914 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0338 - val_accuracy: 0.9917 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0325 - val_accuracy: 0.9919 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0327 - val_accuracy: 0.9919 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0364 - val_accuracy: 0.9901 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0335 - val_accuracy: 0.9919 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0336 - val_accuracy: 0.9917 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0322 - val_accuracy: 0.9930 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0323 - val_accuracy: 0.9930 - lr: 2.3644e-04\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0339 - val_accuracy: 0.9917 - lr: 2.3357e-04\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.0343 - val_accuracy: 0.9912 - lr: 2.3087e-04\n",
      "Epoch 33/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0361 - val_accuracy: 0.9904 - lr: 2.2832e-04\n",
      "Epoch 34/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0329 - val_accuracy: 0.9930 - lr: 2.2590e-04\n",
      "Epoch 35/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0324 - val_accuracy: 0.9930 - lr: 2.2361e-04\n",
      "Epoch 36/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0327 - val_accuracy: 0.9930 - lr: 2.2143e-04\n",
      "Epoch 37/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0344 - val_accuracy: 0.9914 - lr: 2.1935e-04\n",
      "Epoch 38/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0331 - val_accuracy: 0.9935 - lr: 2.1736e-04\n",
      "Epoch 39/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0355 - val_accuracy: 0.9912 - lr: 2.1546e-04\n",
      "Saved model to models/model_16_FF_soft_16_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = soft, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 27s 54ms/step - loss: 0.6895 - accuracy: 0.5407 - val_loss: 0.6793 - val_accuracy: 0.6315 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 17s 35ms/step - loss: 0.5962 - accuracy: 0.7914 - val_loss: 0.4376 - val_accuracy: 0.9053 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 12s 24ms/step - loss: 0.2355 - accuracy: 0.9518 - val_loss: 0.1093 - val_accuracy: 0.9763 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0693 - accuracy: 0.9842 - val_loss: 0.0617 - val_accuracy: 0.9807 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 8s 16ms/step - loss: 0.0428 - accuracy: 0.9883 - val_loss: 0.0488 - val_accuracy: 0.9846 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0311 - accuracy: 0.9911 - val_loss: 0.0421 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0467 - val_accuracy: 0.9857 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0393 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0379 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0348 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 0.0403 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0453 - val_accuracy: 0.9886 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 0.0316 - val_accuracy: 0.9909 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0333 - val_accuracy: 0.9901 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0341 - val_accuracy: 0.9901 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0337 - val_accuracy: 0.9901 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0326 - val_accuracy: 0.9909 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0323 - val_accuracy: 0.9909 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0349 - val_accuracy: 0.9899 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0310 - val_accuracy: 0.9912 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0349 - val_accuracy: 0.9901 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0334 - val_accuracy: 0.9914 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0345 - val_accuracy: 0.9904 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0327 - val_accuracy: 0.9912 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0375 - val_accuracy: 0.9904 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0343 - val_accuracy: 0.9904 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0333 - val_accuracy: 0.9909 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0328 - val_accuracy: 0.9917 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0362 - val_accuracy: 0.9901 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0349 - val_accuracy: 0.9912 - lr: 2.3644e-04\n",
      "Saved model to models/model_16_FF_soft_64_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 1, n_lstm = 0, attention_type = soft, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 28s 55ms/step - loss: 0.6890 - accuracy: 0.5417 - val_loss: 0.6779 - val_accuracy: 0.7080 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 17s 35ms/step - loss: 0.6108 - accuracy: 0.7554 - val_loss: 0.4832 - val_accuracy: 0.8910 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 13s 26ms/step - loss: 0.2764 - accuracy: 0.9464 - val_loss: 0.1257 - val_accuracy: 0.9724 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 9s 19ms/step - loss: 0.0748 - accuracy: 0.9837 - val_loss: 0.0579 - val_accuracy: 0.9815 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 8s 17ms/step - loss: 0.0429 - accuracy: 0.9884 - val_loss: 0.0514 - val_accuracy: 0.9852 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0370 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0394 - val_accuracy: 0.9870 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0193 - accuracy: 0.9953 - val_loss: 0.0312 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0297 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0137 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9896 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.0294 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0281 - val_accuracy: 0.9914 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0269 - val_accuracy: 0.9919 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0285 - val_accuracy: 0.9917 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0271 - val_accuracy: 0.9925 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0264 - val_accuracy: 0.9927 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0263 - val_accuracy: 0.9927 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0276 - val_accuracy: 0.9919 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0268 - val_accuracy: 0.9922 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0287 - val_accuracy: 0.9914 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0259 - val_accuracy: 0.9930 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0256 - val_accuracy: 0.9935 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0281 - val_accuracy: 0.9919 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0258 - val_accuracy: 0.9935 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0266 - val_accuracy: 0.9932 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 5ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0289 - val_accuracy: 0.9917 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0293 - val_accuracy: 0.9917 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0265 - val_accuracy: 0.9932 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0267 - val_accuracy: 0.9930 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0263 - val_accuracy: 0.9935 - lr: 2.3644e-04\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0276 - val_accuracy: 0.9927 - lr: 2.3357e-04\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0279 - val_accuracy: 0.9927 - lr: 2.3087e-04\n",
      "Saved model to models/model_16_FF_soft_64_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = soft, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 47s 94ms/step - loss: 0.6867 - accuracy: 0.5769 - val_loss: 0.6691 - val_accuracy: 0.6836 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 30s 62ms/step - loss: 0.5599 - accuracy: 0.7784 - val_loss: 0.3572 - val_accuracy: 0.8816 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 21s 43ms/step - loss: 0.1711 - accuracy: 0.9622 - val_loss: 0.0902 - val_accuracy: 0.9703 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 15s 31ms/step - loss: 0.0698 - accuracy: 0.9808 - val_loss: 0.0716 - val_accuracy: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 13s 26ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 0.0450 - val_accuracy: 0.9844 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 10s 21ms/step - loss: 0.0309 - accuracy: 0.9908 - val_loss: 0.0375 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 10s 21ms/step - loss: 0.0235 - accuracy: 0.9936 - val_loss: 0.0362 - val_accuracy: 0.9880 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 9s 18ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0321 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 7s 15ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0303 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.0324 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0295 - val_accuracy: 0.9917 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0337 - val_accuracy: 0.9906 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0312 - val_accuracy: 0.9912 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0297 - val_accuracy: 0.9917 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0267 - val_accuracy: 0.9925 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0303 - val_accuracy: 0.9914 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0271 - val_accuracy: 0.9919 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0287 - val_accuracy: 0.9917 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0270 - val_accuracy: 0.9927 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0273 - val_accuracy: 0.9927 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0268 - val_accuracy: 0.9927 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0291 - val_accuracy: 0.9927 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0273 - val_accuracy: 0.9930 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0268 - val_accuracy: 0.9932 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0275 - val_accuracy: 0.9938 - lr: 2.5407e-04\n",
      "Saved model to models/model_64_FF_soft_16_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = soft, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 28s 56ms/step - loss: 0.6865 - accuracy: 0.5630 - val_loss: 0.6722 - val_accuracy: 0.6737 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 18s 36ms/step - loss: 0.5900 - accuracy: 0.7508 - val_loss: 0.4050 - val_accuracy: 0.9256 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 14s 29ms/step - loss: 0.2197 - accuracy: 0.9573 - val_loss: 0.1066 - val_accuracy: 0.9683 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 10s 21ms/step - loss: 0.0858 - accuracy: 0.9801 - val_loss: 0.0641 - val_accuracy: 0.9774 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 8s 17ms/step - loss: 0.0553 - accuracy: 0.9859 - val_loss: 0.0551 - val_accuracy: 0.9820 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 7s 13ms/step - loss: 0.0375 - accuracy: 0.9896 - val_loss: 0.0408 - val_accuracy: 0.9865 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0269 - accuracy: 0.9928 - val_loss: 0.0445 - val_accuracy: 0.9862 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.0456 - val_accuracy: 0.9857 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.0392 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0367 - val_accuracy: 0.9891 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0314 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0311 - val_accuracy: 0.9912 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.0338 - val_accuracy: 0.9906 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0310 - val_accuracy: 0.9914 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.0313 - val_accuracy: 0.9914 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0305 - val_accuracy: 0.9917 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0299 - val_accuracy: 0.9922 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.0303 - val_accuracy: 0.9919 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9925 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0354 - val_accuracy: 0.9922 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0310 - val_accuracy: 0.9919 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0327 - val_accuracy: 0.9919 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0330 - val_accuracy: 0.9919 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0331 - val_accuracy: 0.9919 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0306 - val_accuracy: 0.9930 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0394 - val_accuracy: 0.9914 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0319 - val_accuracy: 0.9922 - lr: 2.4624e-04\n",
      "Saved model to models/model_64_FF_soft_16_0.5\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = soft, units = 64, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 29s 58ms/step - loss: 0.6890 - accuracy: 0.5427 - val_loss: 0.6771 - val_accuracy: 0.6844 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 18s 37ms/step - loss: 0.5452 - accuracy: 0.7666 - val_loss: 0.2576 - val_accuracy: 0.9503 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 13s 27ms/step - loss: 0.1184 - accuracy: 0.9711 - val_loss: 0.0741 - val_accuracy: 0.9753 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 10s 21ms/step - loss: 0.0519 - accuracy: 0.9856 - val_loss: 0.0597 - val_accuracy: 0.9797 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 9s 18ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0399 - val_accuracy: 0.9857 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 8s 16ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0340 - val_accuracy: 0.9888 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.0290 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0274 - val_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0279 - val_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0260 - val_accuracy: 0.9930 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0308 - val_accuracy: 0.9922 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0327 - val_accuracy: 0.9914 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0258 - val_accuracy: 0.9925 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0276 - val_accuracy: 0.9927 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0270 - val_accuracy: 0.9927 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0258 - val_accuracy: 0.9935 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0254 - val_accuracy: 0.9935 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0263 - val_accuracy: 0.9938 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0249 - val_accuracy: 0.9935 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0283 - val_accuracy: 0.9930 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0288 - val_accuracy: 0.9927 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0246 - val_accuracy: 0.9938 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0296 - val_accuracy: 0.9927 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0276 - val_accuracy: 0.9935 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9930 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0252 - val_accuracy: 0.9938 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0263 - val_accuracy: 0.9940 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0267 - val_accuracy: 0.9940 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0282 - val_accuracy: 0.9932 - lr: 2.3644e-04\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0250 - val_accuracy: 0.9938 - lr: 2.3357e-04\n",
      "Epoch 32/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0286 - val_accuracy: 0.9930 - lr: 2.3087e-04\n",
      "Epoch 33/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0282 - val_accuracy: 0.9935 - lr: 2.2832e-04\n",
      "Saved model to models/model_64_FF_soft_64_0.2\n",
      "Built model with embedding_dim = 64, n_ff = 1, n_lstm = 0, attention_type = soft, units = 64, dropout = 0.5\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 29s 57ms/step - loss: 0.6860 - accuracy: 0.5511 - val_loss: 0.6640 - val_accuracy: 0.7002 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 19s 38ms/step - loss: 0.4704 - accuracy: 0.8226 - val_loss: 0.1667 - val_accuracy: 0.9662 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 13s 26ms/step - loss: 0.0938 - accuracy: 0.9762 - val_loss: 0.0619 - val_accuracy: 0.9787 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 10s 20ms/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.0431 - val_accuracy: 0.9854 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 9s 18ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 0.0353 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 7s 14ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0316 - val_accuracy: 0.9904 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.0407 - val_accuracy: 0.9886 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0303 - val_accuracy: 0.9912 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0265 - val_accuracy: 0.9917 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0268 - val_accuracy: 0.9925 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0253 - val_accuracy: 0.9927 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0404 - val_accuracy: 0.9888 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0274 - val_accuracy: 0.9925 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0270 - val_accuracy: 0.9927 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0268 - val_accuracy: 0.9930 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0256 - val_accuracy: 0.9930 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0261 - val_accuracy: 0.9932 - lr: 3.0739e-04\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0292 - val_accuracy: 0.9925 - lr: 2.9730e-04\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0254 - val_accuracy: 0.9940 - lr: 2.8868e-04\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0250 - val_accuracy: 0.9935 - lr: 2.8117e-04\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0270 - val_accuracy: 0.9932 - lr: 2.7455e-04\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0257 - val_accuracy: 0.9938 - lr: 2.6864e-04\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0273 - val_accuracy: 0.9932 - lr: 2.6332e-04\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0251 - val_accuracy: 0.9940 - lr: 2.5849e-04\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0251 - val_accuracy: 0.9940 - lr: 2.5407e-04\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0264 - val_accuracy: 0.9940 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0280 - val_accuracy: 0.9938 - lr: 2.4624e-04\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 3s 7ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0283 - val_accuracy: 0.9935 - lr: 2.4275e-04\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 4s 7ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0278 - val_accuracy: 0.9938 - lr: 2.3949e-04\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 3s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0307 - val_accuracy: 0.9927 - lr: 2.3644e-04\n",
      "Saved model to models/model_64_FF_soft_64_0.5\n"
     ]
    }
   ],
   "source": [
    "train_models_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T10:43:02.768432Z",
     "iopub.status.busy": "2024-02-04T10:43:02.768052Z",
     "iopub.status.idle": "2024-02-04T12:00:48.987932Z",
     "shell.execute_reply": "2024-02-04T12:00:48.987035Z",
     "shell.execute_reply.started": "2024-02-04T10:43:02.768402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = sdp, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1707043385.898007      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707043387.560805     109 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.8827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707043477.614374      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 102s 202ms/step - loss: 0.2742 - accuracy: 0.8827 - val_loss: 0.0630 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 82s 169ms/step - loss: 0.0593 - accuracy: 0.9801 - val_loss: 0.1066 - val_accuracy: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 76s 156ms/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0394 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 67s 137ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0438 - val_accuracy: 0.9849 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 69s 142ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0275 - val_accuracy: 0.9919 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 62s 126ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0288 - val_accuracy: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 61s 124ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.0573 - val_accuracy: 0.9818 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 60s 124ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0649 - val_accuracy: 0.9797 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9938 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 59s 121ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0263 - val_accuracy: 0.9919 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 58s 118ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0449 - val_accuracy: 0.9859 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 59s 120ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 0.0255 - val_accuracy: 0.9925 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 58s 118ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0413 - val_accuracy: 0.9859 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0245 - val_accuracy: 0.9925 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 58s 119ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0300 - val_accuracy: 0.9912 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0232 - val_accuracy: 0.9930 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0306 - val_accuracy: 0.9909 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 58s 118ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0480 - val_accuracy: 0.9859 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0272 - val_accuracy: 0.9919 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0240 - val_accuracy: 0.9927 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 56s 116ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0257 - val_accuracy: 0.9925 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0250 - val_accuracy: 0.9925 - lr: 2.4254e-05\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0253 - val_accuracy: 0.9925 - lr: 2.3570e-05\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0238 - val_accuracy: 0.9927 - lr: 2.2942e-05\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 56s 116ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0289 - val_accuracy: 0.9912 - lr: 2.2361e-05\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 56s 116ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.0289 - val_accuracy: 0.9912 - lr: 2.1822e-05\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.2\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = sdp, units = 16, dropout = 0.5\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707045004.952354      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.8445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707045079.799554      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 85s 170ms/step - loss: 0.3640 - accuracy: 0.8445 - val_loss: 0.3630 - val_accuracy: 0.8441 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 72s 148ms/step - loss: 0.0761 - accuracy: 0.9738 - val_loss: 0.0456 - val_accuracy: 0.9880 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 65s 133ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 0.0593 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.0400 - val_accuracy: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 64s 131ms/step - loss: 0.0229 - accuracy: 0.9928 - val_loss: 0.0313 - val_accuracy: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 60s 123ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0686 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 62s 126ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0299 - val_accuracy: 0.9922 - lr: 7.0711e-05\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 62s 128ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.0271 - val_accuracy: 0.9932 - lr: 5.7735e-05\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 58s 118ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0319 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9922 - lr: 4.4721e-05\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 58s 119ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0318 - val_accuracy: 0.9922 - lr: 4.0825e-05\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 61s 124ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.0264 - val_accuracy: 0.9930 - lr: 3.7796e-05\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 57s 118ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0298 - val_accuracy: 0.9919 - lr: 3.5355e-05\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 58s 118ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0314 - val_accuracy: 0.9922 - lr: 3.3333e-05\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0314 - val_accuracy: 0.9922 - lr: 3.1623e-05\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0500 - val_accuracy: 0.9872 - lr: 3.0151e-05\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.0447 - val_accuracy: 0.9880 - lr: 2.8868e-05\n",
      "Epoch 18/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0386 - val_accuracy: 0.9891 - lr: 2.7735e-05\n",
      "Epoch 19/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0292 - val_accuracy: 0.9930 - lr: 2.6726e-05\n",
      "Epoch 20/100\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0300 - val_accuracy: 0.9927 - lr: 2.5820e-05\n",
      "Epoch 21/100\n",
      "488/488 [==============================] - 60s 123ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0264 - val_accuracy: 0.9925 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0389 - val_accuracy: 0.9901 - lr: 2.4254e-05\n",
      "Epoch 23/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0302 - val_accuracy: 0.9930 - lr: 2.3570e-05\n",
      "Epoch 24/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0274 - val_accuracy: 0.9922 - lr: 2.2942e-05\n",
      "Epoch 25/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0312 - val_accuracy: 0.9932 - lr: 2.2361e-05\n",
      "Epoch 26/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0450 - val_accuracy: 0.9883 - lr: 2.1822e-05\n",
      "Epoch 27/100\n",
      "488/488 [==============================] - 56s 116ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0269 - val_accuracy: 0.9925 - lr: 2.1320e-05\n",
      "Epoch 28/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0303 - val_accuracy: 0.9930 - lr: 2.0851e-05\n",
      "Epoch 29/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0275 - val_accuracy: 0.9927 - lr: 2.0412e-05\n",
      "Epoch 30/100\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0357 - val_accuracy: 0.9909 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9925 - lr: 1.9612e-05\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.5\n",
      "Built model with embedding_dim = 16, n_ff = 0, n_lstm = 1, attention_type = soft, units = 16, dropout = 0.2\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 55s 109ms/step - loss: 0.6922 - accuracy: 0.5311 - val_loss: 0.6840 - val_accuracy: 0.6742 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "488/488 [==============================] - 43s 88ms/step - loss: 0.3551 - accuracy: 0.8730 - val_loss: 0.1726 - val_accuracy: 0.9584 - lr: 5.0000e-04\n",
      "Epoch 3/100\n",
      "488/488 [==============================] - 40s 82ms/step - loss: 0.1064 - accuracy: 0.9752 - val_loss: 0.0999 - val_accuracy: 0.9794 - lr: 5.0000e-04\n",
      "Epoch 4/100\n",
      "488/488 [==============================] - 35s 73ms/step - loss: 0.0549 - accuracy: 0.9890 - val_loss: 0.0887 - val_accuracy: 0.9823 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 34s 70ms/step - loss: 0.0408 - accuracy: 0.9924 - val_loss: 0.0599 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 33s 68ms/step - loss: 0.0325 - accuracy: 0.9943 - val_loss: 0.0487 - val_accuracy: 0.9893 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 30s 60ms/step - loss: 0.0303 - accuracy: 0.9945 - val_loss: 0.0510 - val_accuracy: 0.9909 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 28s 58ms/step - loss: 0.0291 - accuracy: 0.9951 - val_loss: 0.0497 - val_accuracy: 0.9914 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 31s 63ms/step - loss: 0.0267 - accuracy: 0.9954 - val_loss: 0.0434 - val_accuracy: 0.9917 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "125/488 [======>.......................] - ETA: 18s - loss: 0.0318 - accuracy: 0.9945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 36s 73ms/step - loss: 0.0633 - accuracy: 0.9870 - val_loss: 0.0548 - val_accuracy: 0.9891 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "488/488 [==============================] - 32s 66ms/step - loss: 0.0478 - accuracy: 0.9908 - val_loss: 0.0599 - val_accuracy: 0.9870 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "488/488 [==============================] - 29s 60ms/step - loss: 0.0397 - accuracy: 0.9926 - val_loss: 0.0592 - val_accuracy: 0.9883 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "488/488 [==============================] - 31s 65ms/step - loss: 0.0337 - accuracy: 0.9939 - val_loss: 0.0321 - val_accuracy: 0.9940 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "488/488 [==============================] - 28s 57ms/step - loss: 0.0309 - accuracy: 0.9944 - val_loss: 0.0482 - val_accuracy: 0.9914 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "488/488 [==============================] - 27s 55ms/step - loss: 0.0255 - accuracy: 0.9956 - val_loss: 0.0412 - val_accuracy: 0.9927 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "488/488 [==============================] - 27s 56ms/step - loss: 0.0285 - accuracy: 0.9949 - val_loss: 0.0532 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "488/488 [==============================] - 27s 55ms/step - loss: 0.0258 - accuracy: 0.9954 - val_loss: 0.0430 - val_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "488/488 [==============================] - 28s 57ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.1546 - val_accuracy: 0.9753 - lr: 4.2045e-04\n",
      "Epoch 13/100\n",
      "488/488 [==============================] - 27s 56ms/step - loss: 0.0158 - accuracy: 0.9973 - val_loss: 0.0439 - val_accuracy: 0.9927 - lr: 3.7992e-04\n",
      "Epoch 14/100\n",
      "488/488 [==============================] - 27s 55ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.0487 - val_accuracy: 0.9917 - lr: 3.5355e-04\n",
      "Epoch 15/100\n",
      "488/488 [==============================] - 26s 54ms/step - loss: 0.0147 - accuracy: 0.9975 - val_loss: 0.0397 - val_accuracy: 0.9927 - lr: 3.3437e-04\n",
      "Epoch 16/100\n",
      "488/488 [==============================] - 26s 54ms/step - loss: 0.0151 - accuracy: 0.9977 - val_loss: 0.0411 - val_accuracy: 0.9935 - lr: 3.1947e-04\n",
      "Epoch 17/100\n",
      "488/488 [==============================] - 27s 54ms/step - loss: 0.0164 - accuracy: 0.9974 - val_loss: 0.0668 - val_accuracy: 0.9901 - lr: 3.0739e-04\n",
      "Saved model to models/model_16_LSTM_soft_16_0.5\n"
     ]
    }
   ],
   "source": [
    "train_models_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T12:00:48.991549Z",
     "iopub.status.busy": "2024-02-04T12:00:48.991266Z",
     "iopub.status.idle": "2024-02-04T12:01:17.415803Z",
     "shell.execute_reply": "2024-02-04T12:01:17.415025Z",
     "shell.execute_reply.started": "2024-02-04T12:00:48.991526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/models.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive('models', format='zip', root_dir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models on the validation data and continue training on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttfFQFC9kf1X"
   },
   "source": [
    "Now that we have built the models we are ready to evaluate them on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:05.878357Z",
     "iopub.status.busy": "2024-02-05T00:56:05.878022Z",
     "iopub.status.idle": "2024-02-05T00:56:06.536413Z",
     "shell.execute_reply": "2024-02-05T00:56:06.535325Z",
     "shell.execute_reply.started": "2024-02-05T00:56:05.878326Z"
    },
    "id": "6t0iPZ6XAN-L"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "val_results = []\n",
    "y_val_ = np.transpose(y_val)[1]\n",
    "\n",
    "def make_val_results(embedding_dim, n_ff, n_lstm, attention_type, units, dropout):\n",
    "    model = load_model(get_model_path(embedding_dim, n_ff, n_lstm, attention_type, units, dropout))\n",
    "    y_proba = np.transpose(model.predict(X_val))[1]\n",
    "    y_pred = y_proba > .5\n",
    "    val_results.append({'embedding dim.': embedding_dim,\n",
    "                        'ff or lstm': 'ff' if n_ff != 0 else 'lstm',\n",
    "                        'attention': attention_type,\n",
    "                        'units': units,\n",
    "                        'dropout': dropout,\n",
    "                        'accuracy': accuracy_score(y_val_, y_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:06.538505Z",
     "iopub.status.busy": "2024-02-05T00:56:06.537735Z",
     "iopub.status.idle": "2024-02-05T00:56:06.547641Z",
     "shell.execute_reply": "2024-02-05T00:56:06.546724Z",
     "shell.execute_reply.started": "2024-02-05T00:56:06.538476Z"
    }
   },
   "outputs": [],
   "source": [
    "def val_models_1():\n",
    "    for FF in [True, False]:\n",
    "        for embedding_dim in [16, 64]:\n",
    "            for units in [16, 64]:\n",
    "                for dropout in [0.2,0.5]:\n",
    "                    make_val_results(embedding_dim, 1 if FF else 0, 0 if FF else 1, None, units, dropout)    \n",
    "\n",
    "def val_models_2():\n",
    "    for embedding_dim in [16, 64]:\n",
    "        for units in [16, 64]:\n",
    "            for dropout in [0.2,0.5]:\n",
    "                make_val_results(embedding_dim, 1, 0, 'sdp', units, dropout)\n",
    "        \n",
    "def val_models_3():\n",
    "    for embedding_dim in [16, 64]:\n",
    "        for units in [16, 64]:\n",
    "            for dropout in [0.2,0.5]:\n",
    "                make_val_results(embedding_dim, 1, 0, 'soft', units, dropout)\n",
    "\n",
    "def val_models_4():\n",
    "    for attention_type in ['sdp', 'soft']:\n",
    "        for dropout in [0.2,0.5]:\n",
    "            make_val_results(16, 0, 1, attention_type, 16, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:56:06.549411Z",
     "iopub.status.busy": "2024-02-05T00:56:06.549058Z",
     "iopub.status.idle": "2024-02-05T00:57:51.470330Z",
     "shell.execute_reply": "2024-02-05T00:57:51.469385Z",
     "shell.execute_reply.started": "2024-02-05T00:56:06.549379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 22ms/step\n",
      "121/121 [==============================] - 3s 22ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 20ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 23ms/step\n",
      "121/121 [==============================] - 3s 24ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "121/121 [==============================] - 0s 2ms/step\n",
      "  2/121 [..............................] - ETA: 7s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1707094649.147725      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 5s 39ms/step\n",
      "  2/121 [..............................] - ETA: 7s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707094656.587564      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 5s 39ms/step\n",
      "121/121 [==============================] - 3s 21ms/step\n",
      "121/121 [==============================] - 4s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "val_models_1()\n",
    "val_models_2()\n",
    "val_models_3()\n",
    "val_models_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:57:51.471964Z",
     "iopub.status.busy": "2024-02-05T00:57:51.471612Z",
     "iopub.status.idle": "2024-02-05T00:57:51.497655Z",
     "shell.execute_reply": "2024-02-05T00:57:51.496708Z",
     "shell.execute_reply.started": "2024-02-05T00:57:51.471927Z"
    },
    "id": "mkNzR74V8Nou",
    "outputId": "e48e39b7-0a78-41ca-f7e4-fa91809d7a14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding dim.</th>\n",
       "      <th>ff or lstm</th>\n",
       "      <th>attention</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.994796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.994536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.994275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.994275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.994015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.994015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.993755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.993755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.993495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.993495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.993495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.992194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.992194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.991933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.991933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.991673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.991153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>soft</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.991153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.991153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.990893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.990893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    embedding dim. ff or lstm attention  units  dropout  accuracy\n",
       "14              64       lstm      None     64      0.2  0.994796\n",
       "23              64         ff       sdp     64      0.5  0.994536\n",
       "10              16       lstm      None     64      0.2  0.994275\n",
       "15              64       lstm      None     64      0.5  0.994275\n",
       "21              64         ff       sdp     16      0.5  0.994015\n",
       "35              16       lstm      soft     16      0.5  0.994015\n",
       "17              16         ff       sdp     16      0.5  0.993755\n",
       "11              16       lstm      None     64      0.5  0.993755\n",
       "30              64         ff      soft     64      0.2  0.993755\n",
       "27              16         ff      soft     64      0.5  0.993495\n",
       "31              64         ff      soft     64      0.5  0.993495\n",
       "3               16         ff      None     64      0.5  0.993495\n",
       "20              64         ff       sdp     16      0.2  0.993495\n",
       "22              64         ff       sdp     64      0.2  0.993234\n",
       "12              64       lstm      None     16      0.2  0.993234\n",
       "16              16         ff       sdp     16      0.2  0.992974\n",
       "25              16         ff      soft     16      0.5  0.992974\n",
       "32              16       lstm       sdp     16      0.2  0.992974\n",
       "9               16       lstm      None     16      0.5  0.992974\n",
       "19              16         ff       sdp     64      0.5  0.992974\n",
       "6               64         ff      None     64      0.2  0.992714\n",
       "34              16       lstm      soft     16      0.2  0.992714\n",
       "0               16         ff      None     16      0.2  0.992454\n",
       "28              64         ff      soft     16      0.2  0.992454\n",
       "33              16       lstm       sdp     16      0.5  0.992454\n",
       "29              64         ff      soft     16      0.5  0.992194\n",
       "18              16         ff       sdp     64      0.2  0.992194\n",
       "13              64       lstm      None     16      0.5  0.992194\n",
       "24              16         ff      soft     16      0.2  0.991933\n",
       "1               16         ff      None     16      0.5  0.991933\n",
       "7               64         ff      None     64      0.5  0.991673\n",
       "4               64         ff      None     16      0.2  0.991153\n",
       "26              16         ff      soft     64      0.2  0.991153\n",
       "8               16       lstm      None     16      0.2  0.991153\n",
       "2               16         ff      None     64      0.2  0.990893\n",
       "5               64         ff      None     16      0.5  0.990893"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results_df = pd.DataFrame(val_results)\n",
    "val_results_df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUHACAsODXUo"
   },
   "source": [
    "There is only a very small variation in the accuracy of the 36 different models, which may not be statistically significant. Since we have only trained the models on the training data (after the train-validation split), we can improve the generalization of the models by further training them on the full training data (before the train-validation split). For each of the 36 models we have trained, we will make 3 further models, which are trained for 4, 8, and 12 further epochs, with a scheduled learning rate that decreases as $1/n_{epoch}$ from an initial learning rate of 5e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:57:51.501652Z",
     "iopub.status.busy": "2024-02-05T00:57:51.501353Z",
     "iopub.status.idle": "2024-02-05T00:57:51.506623Z",
     "shell.execute_reply": "2024-02-05T00:57:51.505589Z",
     "shell.execute_reply.started": "2024-02-05T00:57:51.501626Z"
    }
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr, continuing_learning_rate):\n",
    "    return continuing_learning_rate/(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:57:51.508559Z",
     "iopub.status.busy": "2024-02-05T00:57:51.508129Z",
     "iopub.status.idle": "2024-02-05T00:57:51.632277Z",
     "shell.execute_reply": "2024-02-05T00:57:51.631295Z",
     "shell.execute_reply.started": "2024-02-05T00:57:51.508523Z"
    },
    "id": "WXhliRQVNBZ9"
   },
   "outputs": [],
   "source": [
    "X_train_full = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train_full = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T00:57:51.633841Z",
     "iopub.status.busy": "2024-02-05T00:57:51.633545Z",
     "iopub.status.idle": "2024-02-05T00:57:51.641133Z",
     "shell.execute_reply": "2024-02-05T00:57:51.640106Z",
     "shell.execute_reply.started": "2024-02-05T00:57:51.633816Z"
    },
    "id": "lYlrebxQNFaT"
   },
   "outputs": [],
   "source": [
    "def continue_training(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print('Loaded model from ' + model_path)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=5e-5), metrics = ['accuracy'])\n",
    "\n",
    "    continuing_learning_rate = 5e-5\n",
    "    for i in range(3):\n",
    "        model.fit(X_train_full, y_train_full, epochs = 4, validation_data = (X_val, y_val), batch_size = batch_size,\n",
    "                 callbacks = [LearningRateScheduler(lambda epoch, lr: lr_scheduler(epoch, lr, continuing_learning_rate))])\n",
    "        model.save(model_path+f'_continued_on_full_{i+1}')\n",
    "        print('Saved model to ' + model_path + f'_continued_on_full_{i+1}')\n",
    "        continuing_learning_rate /= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T13:57:07.955587Z",
     "iopub.status.busy": "2024-02-04T13:57:07.955253Z",
     "iopub.status.idle": "2024-02-04T14:25:04.594031Z",
     "shell.execute_reply": "2024-02-04T14:25:04.593055Z",
     "shell.execute_reply.started": "2024-02-04T13:57:07.955557Z"
    },
    "id": "YrXl5Z8iDOzX",
    "outputId": "74e092af-f288-4dd8-9ac0-24c4bb6e1e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from models/model_16_FF__16_0.2\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707055031.550935     111 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 20s 115ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0195 - val_accuracy: 0.9940 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 96ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0183 - val_accuracy: 0.9945 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 14s 90ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0176 - val_accuracy: 0.9951 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 11s 70ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0169 - val_accuracy: 0.9948 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF__16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0165 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 8s 51ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0163 - val_accuracy: 0.9951 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0162 - val_accuracy: 0.9953 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 8s 51ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0161 - val_accuracy: 0.9958 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF__16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0160 - val_accuracy: 0.9958 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0160 - val_accuracy: 0.9958 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0160 - val_accuracy: 0.9958 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 30ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0159 - val_accuracy: 0.9958 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF__16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF__16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 73ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0233 - val_accuracy: 0.9927 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 68ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0226 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0214 - val_accuracy: 0.9935 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 56ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.0208 - val_accuracy: 0.9938 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF__16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0203 - val_accuracy: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0202 - val_accuracy: 0.9938 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0200 - val_accuracy: 0.9938 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0199 - val_accuracy: 0.9938 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF__16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0198 - val_accuracy: 0.9938 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0198 - val_accuracy: 0.9938 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0198 - val_accuracy: 0.9938 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 3s 17ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0198 - val_accuracy: 0.9938 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF__16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_FF__64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 69ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0231 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 61ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0206 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0198 - val_accuracy: 0.9935 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 48ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0189 - val_accuracy: 0.9943 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF__64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0185 - val_accuracy: 0.9943 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0182 - val_accuracy: 0.9945 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0180 - val_accuracy: 0.9948 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0178 - val_accuracy: 0.9948 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF__64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0177 - val_accuracy: 0.9948 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0177 - val_accuracy: 0.9948 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0177 - val_accuracy: 0.9948 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0176 - val_accuracy: 0.9948 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF__64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF__64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 67ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0187 - val_accuracy: 0.9953 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 56ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0172 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0162 - val_accuracy: 0.9961 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0156 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF__64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0151 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0148 - val_accuracy: 0.9961 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0147 - val_accuracy: 0.9964 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0146 - val_accuracy: 0.9964 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF__64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0145 - val_accuracy: 0.9964 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0144 - val_accuracy: 0.9964 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0144 - val_accuracy: 0.9964 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0144 - val_accuracy: 0.9964 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF__64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF__16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 19s 118ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0202 - val_accuracy: 0.9935 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0177 - val_accuracy: 0.9940 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 13s 87ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0166 - val_accuracy: 0.9948 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0158 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF__16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 70ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0150 - val_accuracy: 0.9953 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 64ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0148 - val_accuracy: 0.9956 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 55ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0146 - val_accuracy: 0.9956 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 50ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.0144 - val_accuracy: 0.9958 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF__16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0143 - val_accuracy: 0.9958 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0143 - val_accuracy: 0.9958 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0142 - val_accuracy: 0.9958 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0142 - val_accuracy: 0.9958 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF__16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF__16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0223 - val_accuracy: 0.9940 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 11s 71ms/step - loss: 0.0077 - accuracy: 0.9986 - val_loss: 0.0199 - val_accuracy: 0.9943 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0179 - val_accuracy: 0.9945 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0169 - val_accuracy: 0.9948 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF__16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0163 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0159 - val_accuracy: 0.9951 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0157 - val_accuracy: 0.9953 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0156 - val_accuracy: 0.9953 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF__16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0154 - val_accuracy: 0.9953 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.0153 - val_accuracy: 0.9953 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0153 - val_accuracy: 0.9953 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 33ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0153 - val_accuracy: 0.9953 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF__16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF__64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 72ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0201 - val_accuracy: 0.9940 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 61ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0168 - val_accuracy: 0.9951 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 55ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0159 - val_accuracy: 0.9953 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0145 - val_accuracy: 0.9961 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF__64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 46ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0140 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0134 - val_accuracy: 0.9964 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0132 - val_accuracy: 0.9964 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0131 - val_accuracy: 0.9964 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF__64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0129 - val_accuracy: 0.9964 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0129 - val_accuracy: 0.9964 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0128 - val_accuracy: 0.9964 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0128 - val_accuracy: 0.9964 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF__64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF__64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 69ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0181 - val_accuracy: 0.9943 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0156 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 54ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0139 - val_accuracy: 0.9964 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 57ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0131 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF__64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 50ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0123 - val_accuracy: 0.9966 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0119 - val_accuracy: 0.9969 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0117 - val_accuracy: 0.9971 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0116 - val_accuracy: 0.9971 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF__64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0114 - val_accuracy: 0.9971 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0114 - val_accuracy: 0.9971 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 26ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0113 - val_accuracy: 0.9971 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0113 - val_accuracy: 0.9971 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF__64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM__16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 20s 118ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.0280 - val_accuracy: 0.9925 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 17s 110ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0259 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 99ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0246 - val_accuracy: 0.9930 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 14s 94ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0238 - val_accuracy: 0.9935 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM__16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 15s 95ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0226 - val_accuracy: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 13s 84ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0225 - val_accuracy: 0.9940 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 13s 85ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0223 - val_accuracy: 0.9940 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 79ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0220 - val_accuracy: 0.9943 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM__16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 13s 83ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0219 - val_accuracy: 0.9943 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0218 - val_accuracy: 0.9943 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0218 - val_accuracy: 0.9943 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.0218 - val_accuracy: 0.9943 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM__16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM__16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 20s 118ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.0281 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 17s 109ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0243 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0232 - val_accuracy: 0.9948 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 96ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0224 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM__16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 90ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0223 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 13s 88ms/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.0219 - val_accuracy: 0.9951 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 12s 82ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0218 - val_accuracy: 0.9953 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 80ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0218 - val_accuracy: 0.9951 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM__16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 81ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0216 - val_accuracy: 0.9951 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 11s 72ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0215 - val_accuracy: 0.9951 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 11s 72ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0215 - val_accuracy: 0.9951 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0215 - val_accuracy: 0.9951 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM__16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM__64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 22s 130ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0273 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 18s 120ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.0181 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0175 - val_accuracy: 0.9961 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0165 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM__64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 0.9966 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 0.9961 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 14s 92ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0157 - val_accuracy: 0.9961 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 98ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0160 - val_accuracy: 0.9964 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM__64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 91ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0158 - val_accuracy: 0.9964 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 13s 89ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0156 - val_accuracy: 0.9961 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 13s 88ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0156 - val_accuracy: 0.9964 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 14s 92ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 0.9964 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM__64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM__64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 22s 132ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.0226 - val_accuracy: 0.9943 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 18s 119ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0206 - val_accuracy: 0.9948 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0214 - val_accuracy: 0.9945 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.0213 - val_accuracy: 0.9945 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM__64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0215 - val_accuracy: 0.9943 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0202 - val_accuracy: 0.9945 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 98ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0202 - val_accuracy: 0.9945 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0201 - val_accuracy: 0.9951 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM__64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0198 - val_accuracy: 0.9951 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 14s 90ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0196 - val_accuracy: 0.9951 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 13s 88ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0196 - val_accuracy: 0.9951 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 13s 84ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0196 - val_accuracy: 0.9951 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM__64_0.5_continued_on_full_3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for row in val_results[0:12]:\n",
    "    continue_training(get_model_path(row['embedding dim.'], 1 if row['ff or lstm'] == 'ff' else 0, 1 if row['ff or lstm'] == 'lstm' else 0, row['attention'], row['units'], row['dropout']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T14:25:04.595772Z",
     "iopub.status.busy": "2024-02-04T14:25:04.595488Z",
     "iopub.status.idle": "2024-02-04T14:26:24.115306Z",
     "shell.execute_reply": "2024-02-04T14:26:24.114430Z",
     "shell.execute_reply.started": "2024-02-04T14:25:04.595747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/models.zip'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.make_archive('models', format='zip', root_dir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T22:21:14.438398Z",
     "iopub.status.busy": "2024-02-04T22:21:14.438108Z",
     "iopub.status.idle": "2024-02-04T23:51:30.938378Z",
     "shell.execute_reply": "2024-02-04T23:51:30.937154Z",
     "shell.execute_reply.started": "2024-02-04T22:21:14.438375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from models/model_64_LSTM__16_0.2\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707085280.162207     112 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 28s 163ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0218 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 22s 147ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0199 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 20s 130ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0184 - val_accuracy: 0.9964 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 20s 133ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.0176 - val_accuracy: 0.9958 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_LSTM__16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 18s 121ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0173 - val_accuracy: 0.9958 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0165 - val_accuracy: 0.9964 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 16s 106ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0163 - val_accuracy: 0.9961 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0162 - val_accuracy: 0.9964 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_LSTM__16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0161 - val_accuracy: 0.9964 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.0160 - val_accuracy: 0.9964 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 13s 88ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0160 - val_accuracy: 0.9964 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 13s 86ms/step - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0160 - val_accuracy: 0.9964 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_LSTM__16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_LSTM__16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 21s 127ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0191 - val_accuracy: 0.9951 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0169 - val_accuracy: 0.9958 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0175 - val_accuracy: 0.9951 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 16s 104ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0159 - val_accuracy: 0.9964 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_LSTM__16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 15s 98ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9969 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 14s 92ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9966 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 14s 90ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0147 - val_accuracy: 0.9969 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 13s 86ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0147 - val_accuracy: 0.9966 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_LSTM__16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 13s 88ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0146 - val_accuracy: 0.9966 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 12s 81ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0146 - val_accuracy: 0.9966 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 12s 81ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0146 - val_accuracy: 0.9966 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 77ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0145 - val_accuracy: 0.9966 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_LSTM__16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_LSTM__64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 23s 137ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0148 - val_accuracy: 0.9964 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 19s 125ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0129 - val_accuracy: 0.9977 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 19s 124ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0138 - val_accuracy: 0.9987 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 17s 114ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0124 - val_accuracy: 0.9987 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_LSTM__64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 17s 111ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0126 - val_accuracy: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 16s 104ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0129 - val_accuracy: 0.9987 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 17s 109ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0125 - val_accuracy: 0.9984 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0123 - val_accuracy: 0.9984 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_LSTM__64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0122 - val_accuracy: 0.9987 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 0.9987 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 99ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0122 - val_accuracy: 0.9984 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 95ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0122 - val_accuracy: 0.9987 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_LSTM__64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_LSTM__64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 22s 133ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0200 - val_accuracy: 0.9953 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 19s 122ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0154 - val_accuracy: 0.9969 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 18s 117ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0156 - val_accuracy: 0.9966 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 19s 123ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0147 - val_accuracy: 0.9974 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_LSTM__64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 18s 118ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0145 - val_accuracy: 0.9971 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0145 - val_accuracy: 0.9979 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0142 - val_accuracy: 0.9977 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 101ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0141 - val_accuracy: 0.9979 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_LSTM__64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0141 - val_accuracy: 0.9979 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 97ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0139 - val_accuracy: 0.9979 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0140 - val_accuracy: 0.9979 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 14s 95ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0139 - val_accuracy: 0.9979 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_LSTM__64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_sdp_16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 40s 258ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.0215 - val_accuracy: 0.9948 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0196 - val_accuracy: 0.9966 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.0198 - val_accuracy: 0.9956 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0184 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_sdp_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0179 - val_accuracy: 0.9964 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0177 - val_accuracy: 0.9964 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.0178 - val_accuracy: 0.9964 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0177 - val_accuracy: 0.9964 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_sdp_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0176 - val_accuracy: 0.9964 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0175 - val_accuracy: 0.9964 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.0174 - val_accuracy: 0.9964 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0174 - val_accuracy: 0.9964 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_sdp_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_sdp_16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 40s 257ms/step - loss: 0.0168 - accuracy: 0.9971 - val_loss: 0.0257 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0232 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0231 - val_accuracy: 0.9951 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.0215 - val_accuracy: 0.9953 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_sdp_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.0209 - val_accuracy: 0.9956 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.0207 - val_accuracy: 0.9958 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0203 - val_accuracy: 0.9953 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.0202 - val_accuracy: 0.9956 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_sdp_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.0200 - val_accuracy: 0.9956 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0200 - val_accuracy: 0.9956 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.0200 - val_accuracy: 0.9956 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0121 - accuracy: 0.9985 - val_loss: 0.0200 - val_accuracy: 0.9956 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_sdp_16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_sdp_64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 40s 259ms/step - loss: 0.0145 - accuracy: 0.9977 - val_loss: 0.0299 - val_accuracy: 0.9938 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0270 - val_accuracy: 0.9948 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0254 - val_accuracy: 0.9943 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0242 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_sdp_64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 253ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0233 - val_accuracy: 0.9951 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0230 - val_accuracy: 0.9951 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0229 - val_accuracy: 0.9956 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.0228 - val_accuracy: 0.9956 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_sdp_64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0227 - val_accuracy: 0.9956 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0226 - val_accuracy: 0.9956 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0225 - val_accuracy: 0.9956 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0224 - val_accuracy: 0.9956 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_sdp_64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_sdp_64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 40s 256ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.0297 - val_accuracy: 0.9943 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 0.0157 - accuracy: 0.9976 - val_loss: 0.0270 - val_accuracy: 0.9940 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0264 - val_accuracy: 0.9935 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 0.0245 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_sdp_64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0107 - accuracy: 0.9980 - val_loss: 0.0236 - val_accuracy: 0.9956 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0125 - accuracy: 0.9980 - val_loss: 0.0232 - val_accuracy: 0.9958 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0124 - accuracy: 0.9981 - val_loss: 0.0233 - val_accuracy: 0.9951 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 0.0125 - accuracy: 0.9979 - val_loss: 0.0228 - val_accuracy: 0.9953 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_sdp_64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0227 - val_accuracy: 0.9951 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0227 - val_accuracy: 0.9951 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.0226 - val_accuracy: 0.9951 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0226 - val_accuracy: 0.9951 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_sdp_64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_sdp_16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 47s 300ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0223 - val_accuracy: 0.9956 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0188 - val_accuracy: 0.9964 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.0174 - val_accuracy: 0.9964 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0166 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_sdp_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0158 - val_accuracy: 0.9969 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0153 - val_accuracy: 0.9969 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0152 - val_accuracy: 0.9969 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0150 - val_accuracy: 0.9974 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_sdp_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0150 - val_accuracy: 0.9969 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 295ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0148 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0148 - val_accuracy: 0.9974 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0148 - val_accuracy: 0.9977 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_sdp_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_sdp_16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 47s 301ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.0215 - val_accuracy: 0.9951 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0132 - accuracy: 0.9976 - val_loss: 0.0191 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 295ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0182 - val_accuracy: 0.9953 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 295ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0207 - val_accuracy: 0.9951 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_sdp_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0169 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0165 - val_accuracy: 0.9966 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.0162 - val_accuracy: 0.9966 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0161 - val_accuracy: 0.9969 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_sdp_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0160 - val_accuracy: 0.9961 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.0159 - val_accuracy: 0.9969 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.0158 - val_accuracy: 0.9966 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0158 - val_accuracy: 0.9969 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_sdp_16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_sdp_64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 46s 298ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.0319 - val_accuracy: 0.9925 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0225 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0215 - val_accuracy: 0.9953 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0238 - val_accuracy: 0.9943 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_sdp_64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0197 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0193 - val_accuracy: 0.9961 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0191 - val_accuracy: 0.9964 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0188 - val_accuracy: 0.9961 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_sdp_64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0187 - val_accuracy: 0.9966 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0187 - val_accuracy: 0.9966 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0186 - val_accuracy: 0.9966 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0186 - val_accuracy: 0.9966 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_sdp_64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_sdp_64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 47s 302ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.0365 - val_accuracy: 0.9945 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.0291 - val_accuracy: 0.9956 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0238 - val_accuracy: 0.9966 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0234 - val_accuracy: 0.9966 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_sdp_64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 296ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.0234 - val_accuracy: 0.9961 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 298ms/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 0.0221 - val_accuracy: 0.9969 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0220 - val_accuracy: 0.9971 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 297ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0216 - val_accuracy: 0.9969 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_sdp_64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 45s 299ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0215 - val_accuracy: 0.9969 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 45s 294ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0215 - val_accuracy: 0.9971 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 45s 293ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0213 - val_accuracy: 0.9969 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 45s 293ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.0213 - val_accuracy: 0.9969 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_sdp_64_0.5_continued_on_full_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/models.zip'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for row in val_results[12:24]:\n",
    "    continue_training(get_model_path(row['embedding dim.'], 1 if row['ff or lstm'] == 'ff' else 0, 1 if row['ff or lstm'] == 'lstm' else 0, row['attention'], row['units'], row['dropout']))\n",
    "shutil.make_archive('models', format='zip', root_dir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T01:00:58.930171Z",
     "iopub.status.busy": "2024-02-05T01:00:58.929546Z",
     "iopub.status.idle": "2024-02-05T01:47:34.771083Z",
     "shell.execute_reply": "2024-02-05T01:47:34.769932Z",
     "shell.execute_reply.started": "2024-02-05T01:00:58.930138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from models/model_16_FF_soft_16_0.2\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707094861.833122     108 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 20s 115ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0288 - val_accuracy: 0.9917 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 98ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0286 - val_accuracy: 0.9919 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 14s 92ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0285 - val_accuracy: 0.9917 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 10s 69ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0284 - val_accuracy: 0.9919 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_soft_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 71ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0283 - val_accuracy: 0.9917 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 64ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.0283 - val_accuracy: 0.9917 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 54ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.0283 - val_accuracy: 0.9917 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 61ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0282 - val_accuracy: 0.9917 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_soft_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0282 - val_accuracy: 0.9917 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 35ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0282 - val_accuracy: 0.9917 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0282 - val_accuracy: 0.9917 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 6s 36ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0282 - val_accuracy: 0.9917 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_soft_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_soft_16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 13s 80ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0318 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0318 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0317 - val_accuracy: 0.9932 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0316 - val_accuracy: 0.9932 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_soft_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0118 - accuracy: 0.9976 - val_loss: 0.0316 - val_accuracy: 0.9932 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0315 - val_accuracy: 0.9932 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0120 - accuracy: 0.9978 - val_loss: 0.0315 - val_accuracy: 0.9932 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0315 - val_accuracy: 0.9932 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_soft_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 5s 36ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0315 - val_accuracy: 0.9932 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.0314 - val_accuracy: 0.9932 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0314 - val_accuracy: 0.9932 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0314 - val_accuracy: 0.9932 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_soft_16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_soft_64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 71ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0309 - val_accuracy: 0.9912 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 60ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.0305 - val_accuracy: 0.9912 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0302 - val_accuracy: 0.9914 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 47ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0300 - val_accuracy: 0.9914 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_soft_64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0299 - val_accuracy: 0.9914 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0298 - val_accuracy: 0.9914 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0298 - val_accuracy: 0.9914 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_soft_64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 27ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0297 - val_accuracy: 0.9914 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_soft_64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_FF_soft_64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 68ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0255 - val_accuracy: 0.9930 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 62ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0253 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0251 - val_accuracy: 0.9930 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 8s 55ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0251 - val_accuracy: 0.9930 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_FF_soft_64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0250 - val_accuracy: 0.9932 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 37ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0250 - val_accuracy: 0.9932 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 38ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_FF_soft_64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0249 - val_accuracy: 0.9932 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_FF_soft_64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_soft_16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 19s 120ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9922 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0266 - val_accuracy: 0.9919 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 95ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.0264 - val_accuracy: 0.9919 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 13s 87ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0262 - val_accuracy: 0.9919 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_soft_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 11s 70ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0261 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 65ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0261 - val_accuracy: 0.9919 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 10s 66ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0261 - val_accuracy: 0.9919 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0261 - val_accuracy: 0.9919 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_soft_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 52ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0260 - val_accuracy: 0.9919 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 44ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0260 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 43ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0260 - val_accuracy: 0.9919 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.0260 - val_accuracy: 0.9919 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_soft_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_soft_16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0297 - val_accuracy: 0.9919 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 68ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.0295 - val_accuracy: 0.9919 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 10s 69ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0294 - val_accuracy: 0.9919 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 8s 55ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0294 - val_accuracy: 0.9917 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_soft_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 51ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0117 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9917 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 7s 49ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0292 - val_accuracy: 0.9917 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 7s 47ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9914 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_soft_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 43ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9914 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 40ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0292 - val_accuracy: 0.9914 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0292 - val_accuracy: 0.9914 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 28ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.0292 - val_accuracy: 0.9917 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_soft_16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_soft_64_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 75ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0241 - val_accuracy: 0.9940 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 10s 68ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0244 - val_accuracy: 0.9938 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 10s 63ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0240 - val_accuracy: 0.9938 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 8s 55ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0239 - val_accuracy: 0.9938 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_soft_64_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 53ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0238 - val_accuracy: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0237 - val_accuracy: 0.9938 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 41ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0237 - val_accuracy: 0.9938 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_soft_64_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 7s 45ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 34ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 25ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_soft_64_0.2_continued_on_full_3\n",
      "Loaded model from models/model_64_FF_soft_64_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 73ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0246 - val_accuracy: 0.9935 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 9s 59ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0243 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0239 - val_accuracy: 0.9935 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 9s 58ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0239 - val_accuracy: 0.9932 - lr: 1.2500e-05\n",
      "Saved model to models/model_64_FF_soft_64_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 8s 51ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0238 - val_accuracy: 0.9932 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.0237 - val_accuracy: 0.9938 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 6s 42ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 5s 32ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 2.5000e-06\n",
      "Saved model to models/model_64_FF_soft_64_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 6s 39ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0236 - val_accuracy: 0.9938 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 5s 31ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0235 - val_accuracy: 0.9938 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 5s 30ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0235 - val_accuracy: 0.9938 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 4s 29ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0235 - val_accuracy: 0.9938 - lr: 5.0000e-07\n",
      "Saved model to models/model_64_FF_soft_64_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM_sdp_16_0.2\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707095700.220479      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707095754.942504      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 60s 379ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0257 - val_accuracy: 0.9914 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 56s 370ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0181 - val_accuracy: 0.9961 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 55s 361ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.0171 - val_accuracy: 0.9964 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 54s 355ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0178 - val_accuracy: 0.9953 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 54s 357ms/step - loss: 0.0078 - accuracy: 0.9984 - val_loss: 0.0167 - val_accuracy: 0.9956 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 52s 344ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0158 - val_accuracy: 0.9961 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 52s 342ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0158 - val_accuracy: 0.9958 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 52s 342ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0162 - val_accuracy: 0.9956 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 53s 350ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 0.9961 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 51s 337ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0154 - val_accuracy: 0.9958 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 52s 343ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 0.9958 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 51s 337ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0155 - val_accuracy: 0.9958 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM_sdp_16_0.5\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707096447.871306      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707096502.589136      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 60s 380ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0212 - val_accuracy: 0.9953 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 56s 368ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9953 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 55s 363ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0188 - val_accuracy: 0.9956 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 55s 359ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0190 - val_accuracy: 0.9953 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 54s 358ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0178 - val_accuracy: 0.9956 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 53s 350ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0176 - val_accuracy: 0.9956 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 53s 352ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0176 - val_accuracy: 0.9956 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 53s 346ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0174 - val_accuracy: 0.9956 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 52s 344ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0174 - val_accuracy: 0.9958 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 51s 338ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0174 - val_accuracy: 0.9958 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 52s 340ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0174 - val_accuracy: 0.9958 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 51s 337ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0174 - val_accuracy: 0.9956 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM_sdp_16_0.5_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM_soft_16_0.2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 20s 119ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.0333 - val_accuracy: 0.9943 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 16s 107ms/step - loss: 0.0127 - accuracy: 0.9979 - val_loss: 0.0377 - val_accuracy: 0.9935 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 15s 101ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 98ms/step - loss: 0.0141 - accuracy: 0.9977 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM_soft_16_0.2_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 94ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0327 - val_accuracy: 0.9943 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 13s 83ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 12s 81ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 80ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM_soft_16_0.2_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 78ms/step - loss: 0.0137 - accuracy: 0.9978 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.0344 - val_accuracy: 0.9940 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 11s 72ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 11s 73ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0345 - val_accuracy: 0.9940 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM_soft_16_0.2_continued_on_full_3\n",
      "Loaded model from models/model_16_LSTM_soft_16_0.5\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 20s 118ms/step - loss: 0.0231 - accuracy: 0.9960 - val_loss: 0.0361 - val_accuracy: 0.9932 - lr: 5.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 16s 103ms/step - loss: 0.0265 - accuracy: 0.9952 - val_loss: 0.0375 - val_accuracy: 0.9930 - lr: 2.5000e-05\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 16s 105ms/step - loss: 0.0227 - accuracy: 0.9959 - val_loss: 0.0380 - val_accuracy: 0.9930 - lr: 1.6667e-05\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 15s 100ms/step - loss: 0.0230 - accuracy: 0.9960 - val_loss: 0.0370 - val_accuracy: 0.9932 - lr: 1.2500e-05\n",
      "Saved model to models/model_16_LSTM_soft_16_0.5_continued_on_full_1\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 14s 93ms/step - loss: 0.0231 - accuracy: 0.9960 - val_loss: 0.0380 - val_accuracy: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 13s 84ms/step - loss: 0.0238 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9932 - lr: 5.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 12s 81ms/step - loss: 0.0256 - accuracy: 0.9955 - val_loss: 0.0343 - val_accuracy: 0.9938 - lr: 3.3333e-06\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 12s 80ms/step - loss: 0.0235 - accuracy: 0.9958 - val_loss: 0.0354 - val_accuracy: 0.9935 - lr: 2.5000e-06\n",
      "Saved model to models/model_16_LSTM_soft_16_0.5_continued_on_full_2\n",
      "Epoch 1/4\n",
      "152/152 [==============================] - 12s 76ms/step - loss: 0.0227 - accuracy: 0.9961 - val_loss: 0.0341 - val_accuracy: 0.9938 - lr: 2.0000e-06\n",
      "Epoch 2/4\n",
      "152/152 [==============================] - 11s 74ms/step - loss: 0.0223 - accuracy: 0.9961 - val_loss: 0.0341 - val_accuracy: 0.9938 - lr: 1.0000e-06\n",
      "Epoch 3/4\n",
      "152/152 [==============================] - 10s 69ms/step - loss: 0.0269 - accuracy: 0.9952 - val_loss: 0.0340 - val_accuracy: 0.9938 - lr: 6.6667e-07\n",
      "Epoch 4/4\n",
      "152/152 [==============================] - 10s 68ms/step - loss: 0.0232 - accuracy: 0.9960 - val_loss: 0.0340 - val_accuracy: 0.9938 - lr: 5.0000e-07\n",
      "Saved model to models/model_16_LSTM_soft_16_0.5_continued_on_full_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/models.zip'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for row in val_results[24:36]:\n",
    "    continue_training(get_model_path(row['embedding dim.'], 1 if row['ff or lstm'] == 'ff' else 0, 1 if row['ff or lstm'] == 'lstm' else 0, row['attention'], row['units'], row['dropout']))\n",
    "shutil.make_archive('models', format='zip', root_dir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D-bgJCxlIsh"
   },
   "source": [
    "We are now finally ready to evaluate our models on the test set. Let's load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T01:48:11.099600Z",
     "iopub.status.busy": "2024-02-05T01:48:11.098860Z",
     "iopub.status.idle": "2024-02-05T01:48:11.369925Z",
     "shell.execute_reply": "2024-02-05T01:48:11.368911Z",
     "shell.execute_reply.started": "2024-02-05T01:48:11.099568Z"
    },
    "id": "kV2AJyqnabFa",
    "outputId": "54912246-3221-4942-ab33-1dee64a8ccbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>TTV split</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LL Cool J performed much better in this movie ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It would be unwise to judge that that either n...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canto 1: How Kriemhild Mourned Over Siegfried ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Will and Ted's Bodacious journey is an existen...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK, so my summary line is a cheap trick. But t...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>A standards organization, also known as a stan...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Standards organization</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>The International Electrotechnical Commission ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>International Electrotechnical Commission</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>Bhutan, officially known as the Kingdom of Bhu...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Bhutan</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>Jigme Khesar Namgyel Wangchuck is a prominent ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Jigme Khesar Namgyel Wangchuck</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>Norodom Sihamoni is the current reigning King ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Norodom Sihamoni</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4749 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text            source  \\\n",
       "0     LL Cool J performed much better in this movie ...              imdb   \n",
       "1     It would be unwise to judge that that either n...              imdb   \n",
       "2     Canto 1: How Kriemhild Mourned Over Siegfried ...              imdb   \n",
       "3     Will and Ted's Bodacious journey is an existen...              imdb   \n",
       "4     OK, so my summary line is a cheap trick. But t...              imdb   \n",
       "...                                                 ...               ...   \n",
       "4744  A standards organization, also known as a stan...  wikipedia by GPT   \n",
       "4745  The International Electrotechnical Commission ...  wikipedia by GPT   \n",
       "4746  Bhutan, officially known as the Kingdom of Bhu...  wikipedia by GPT   \n",
       "4747  Jigme Khesar Namgyel Wangchuck is a prominent ...  wikipedia by GPT   \n",
       "4748  Norodom Sihamoni is the current reigning King ...  wikipedia by GPT   \n",
       "\n",
       "                                          topic  TTV split  label  \n",
       "0                                  movie review       -1.0      0  \n",
       "1                                  movie review       -1.0      0  \n",
       "2                                  movie review       -1.0      0  \n",
       "3                                  movie review       -1.0      0  \n",
       "4                                  movie review       -1.0      0  \n",
       "...                                         ...        ...    ...  \n",
       "4744                     Standards organization       -1.0      1  \n",
       "4745  International Electrotechnical Commission       -1.0      1  \n",
       "4746                                     Bhutan       -1.0      1  \n",
       "4747             Jigme Khesar Namgyel Wangchuck       -1.0      1  \n",
       "4748                           Norodom Sihamoni       -1.0      1  \n",
       "\n",
       "[4749 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(home + 'test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T01:48:55.371819Z",
     "iopub.status.busy": "2024-02-05T01:48:55.370843Z",
     "iopub.status.idle": "2024-02-05T01:48:55.382160Z",
     "shell.execute_reply": "2024-02-05T01:48:55.380935Z",
     "shell.execute_reply.started": "2024-02-05T01:48:55.371777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imdb', 'r/relationship_advice', 'r/AITA', 'wikipedia',\n",
       "       'GPT movie reviews', 'GPT reddit posts', 'wikipedia by GPT'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JichrqyFmFJz"
   },
   "source": [
    "We will have to tokenize and vectorize the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T01:49:07.104105Z",
     "iopub.status.busy": "2024-02-05T01:49:07.103428Z",
     "iopub.status.idle": "2024-02-05T01:49:14.550754Z",
     "shell.execute_reply": "2024-02-05T01:49:14.549920Z",
     "shell.execute_reply.started": "2024-02-05T01:49:07.104073Z"
    },
    "id": "Oabd2ARp9I-t"
   },
   "outputs": [],
   "source": [
    "test['tokenized'] = test['text'].apply(lambda x: ' '.join(tokenizer(x)))\n",
    "X_test  = vectorize_layer(test['tokenized'].tolist()).numpy()\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otbL3XcOmJ6Y"
   },
   "source": [
    "Next, we generate the test scores for the 36 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:40:13.150804Z",
     "iopub.status.busy": "2024-02-05T02:40:13.149940Z",
     "iopub.status.idle": "2024-02-05T02:40:13.158180Z",
     "shell.execute_reply": "2024-02-05T02:40:13.157105Z",
     "shell.execute_reply.started": "2024-02-05T02:40:13.150770Z"
    },
    "id": "XvOtT_yV90cK"
   },
   "outputs": [],
   "source": [
    "test_results = []\n",
    "\n",
    "def make_test_results(embedding_dim, n_ff, n_lstm, attention_type, units, dropout, i):\n",
    "    model_path = get_model_path(embedding_dim, n_ff, n_lstm, attention_type, units, dropout)\n",
    "    if i > 0:\n",
    "        model_path += f'_continued_on_full_{i}'\n",
    "    model = load_model(model_path)\n",
    "    y_proba = np.transpose(model.predict(X_test))[1]\n",
    "    y_pred = y_proba > .5\n",
    "    test_results.append({'embedding dim.': embedding_dim,\n",
    "                        'ff or lstm': 'ff' if n_ff != 0 else 'lstm',\n",
    "                        'attention': attention_type,\n",
    "                        'units': units,\n",
    "                        'dropout': dropout,\n",
    "                        'accuracy': accuracy_score(y_test, y_pred),\n",
    "                        'additional training epochs': i*4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:40:28.890017Z",
     "iopub.status.busy": "2024-02-05T02:40:28.889392Z",
     "iopub.status.idle": "2024-02-05T02:48:42.626248Z",
     "shell.execute_reply": "2024-02-05T02:48:42.625273Z",
     "shell.execute_reply.started": "2024-02-05T02:40:28.889979Z"
    },
    "id": "Y0R4Hlnm9_rn",
    "outputId": "8b587e42-1297-41d0-b9f0-81696e902b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 24ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 24ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 24ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 22ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 3s 21ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 4s 25ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "149/149 [==============================] - 0s 2ms/step\n",
      "  3/149 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101211.086992      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 41ms/step\n",
      "  2/149 [..............................] - ETA: 8s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101219.327879      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101228.604421      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101236.801752      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101245.067237      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101253.216026      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101261.425518      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "  2/149 [..............................] - ETA: 8s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1707101269.544884      34 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"12020\" } environment { key: \"cudnn\" value: \"8904\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14626652160 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 6s 40ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "for row in val_results:\n",
    "    for i in range(4):\n",
    "        make_test_results(row['embedding dim.'], 1 if row['ff or lstm'] == 'ff' else 0, 1 if row['ff or lstm'] == 'lstm' else 0, row['attention'], row['units'], row['dropout'], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:52:03.789081Z",
     "iopub.status.busy": "2024-02-05T02:52:03.788032Z",
     "iopub.status.idle": "2024-02-05T02:52:03.819713Z",
     "shell.execute_reply": "2024-02-05T02:52:03.818665Z",
     "shell.execute_reply.started": "2024-02-05T02:52:03.789035Z"
    },
    "id": "OFgcHEMoMxLl",
    "outputId": "e1f8dff4-0ee6-4c66-e3a2-7a6f5ddcf841"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding dim.</th>\n",
       "      <th>ff or lstm</th>\n",
       "      <th>attention</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>additional training epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997473</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.997263</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.997263</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.997052</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>64</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sdp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>sdp</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64</td>\n",
       "      <td>ff</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16</td>\n",
       "      <td>lstm</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     embedding dim. ff or lstm attention  units  dropout  accuracy  \\\n",
       "61               64       lstm      None     64      0.5  0.997684   \n",
       "62               64       lstm      None     64      0.5  0.997684   \n",
       "63               64       lstm      None     64      0.5  0.997684   \n",
       "131              16       lstm       sdp     16      0.2  0.997684   \n",
       "80               64         ff       sdp     16      0.2  0.997473   \n",
       "65               16         ff       sdp     16      0.2  0.997473   \n",
       "81               64         ff       sdp     16      0.2  0.997263   \n",
       "73               16         ff       sdp     64      0.2  0.997263   \n",
       "86               64         ff       sdp     16      0.5  0.997263   \n",
       "87               64         ff       sdp     16      0.5  0.997263   \n",
       "11               16         ff      None     64      0.2  0.997052   \n",
       "83               64         ff       sdp     16      0.2  0.997052   \n",
       "67               16         ff       sdp     16      0.2  0.997052   \n",
       "10               16         ff      None     64      0.2  0.997052   \n",
       "82               64         ff       sdp     16      0.2  0.997052   \n",
       "75               16         ff       sdp     64      0.2  0.996841   \n",
       "15               16         ff      None     64      0.5  0.996841   \n",
       "90               64         ff       sdp     64      0.2  0.996841   \n",
       "13               16         ff      None     64      0.5  0.996841   \n",
       "9                16         ff      None     64      0.2  0.996841   \n",
       "66               16         ff       sdp     16      0.2  0.996841   \n",
       "14               16         ff      None     64      0.5  0.996841   \n",
       "47               16       lstm      None     64      0.5  0.996841   \n",
       "45               16       lstm      None     64      0.5  0.996841   \n",
       "60               64       lstm      None     64      0.5  0.996841   \n",
       "94               64         ff       sdp     64      0.5  0.996841   \n",
       "78               16         ff       sdp     64      0.5  0.996841   \n",
       "76               16         ff       sdp     64      0.5  0.996841   \n",
       "74               16         ff       sdp     64      0.2  0.996841   \n",
       "84               64         ff       sdp     16      0.5  0.996841   \n",
       "133              16       lstm       sdp     16      0.5  0.996631   \n",
       "130              16       lstm       sdp     16      0.2  0.996631   \n",
       "70               16         ff       sdp     16      0.5  0.996631   \n",
       "71               16         ff       sdp     16      0.5  0.996631   \n",
       "69               16         ff       sdp     16      0.5  0.996631   \n",
       "46               16       lstm      None     64      0.5  0.996631   \n",
       "91               64         ff       sdp     64      0.2  0.996631   \n",
       "92               64         ff       sdp     64      0.5  0.996631   \n",
       "64               16         ff       sdp     16      0.2  0.996631   \n",
       "68               16         ff       sdp     16      0.5  0.996631   \n",
       "95               64         ff       sdp     64      0.5  0.996631   \n",
       "77               16         ff       sdp     64      0.5  0.996631   \n",
       "135              16       lstm       sdp     16      0.5  0.996420   \n",
       "129              16       lstm       sdp     16      0.2  0.996420   \n",
       "93               64         ff       sdp     64      0.5  0.996420   \n",
       "79               16         ff       sdp     64      0.5  0.996420   \n",
       "3                16         ff      None     16      0.2  0.996420   \n",
       "2                16         ff      None     16      0.2  0.996420   \n",
       "29               64         ff      None     64      0.5  0.996210   \n",
       "34               16       lstm      None     16      0.2  0.996210   \n",
       "\n",
       "     additional training epochs  \n",
       "61                            4  \n",
       "62                            8  \n",
       "63                           12  \n",
       "131                          12  \n",
       "80                            0  \n",
       "65                            4  \n",
       "81                            4  \n",
       "73                            4  \n",
       "86                            8  \n",
       "87                           12  \n",
       "11                           12  \n",
       "83                           12  \n",
       "67                           12  \n",
       "10                            8  \n",
       "82                            8  \n",
       "75                           12  \n",
       "15                           12  \n",
       "90                            8  \n",
       "13                            4  \n",
       "9                             4  \n",
       "66                            8  \n",
       "14                            8  \n",
       "47                           12  \n",
       "45                            4  \n",
       "60                            0  \n",
       "94                            8  \n",
       "78                            8  \n",
       "76                            0  \n",
       "74                            8  \n",
       "84                            0  \n",
       "133                           4  \n",
       "130                           8  \n",
       "70                            8  \n",
       "71                           12  \n",
       "69                            4  \n",
       "46                            8  \n",
       "91                           12  \n",
       "92                            0  \n",
       "64                            0  \n",
       "68                            0  \n",
       "95                           12  \n",
       "77                            4  \n",
       "135                          12  \n",
       "129                           4  \n",
       "93                            4  \n",
       "79                           12  \n",
       "3                            12  \n",
       "2                             8  \n",
       "29                            4  \n",
       "34                            8  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_df = pd.DataFrame(test_results)\n",
    "test_results_df.sort_values(by = 'accuracy', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI2FTVp3oJr2"
   },
   "source": [
    "We see that the validation results were slightly lower then the test results, and this is probably just because the validation set was slightly smaller than the test set. Let's produce detailed results for the top 2 performing models on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:03:57.632501Z",
     "iopub.status.busy": "2024-02-05T02:03:57.632137Z",
     "iopub.status.idle": "2024-02-05T02:03:57.639269Z",
     "shell.execute_reply": "2024-02-05T02:03:57.638264Z",
     "shell.execute_reply.started": "2024-02-05T02:03:57.632467Z"
    },
    "id": "JgBerGGEsCtS"
   },
   "outputs": [],
   "source": [
    "def display_results(y_eval, y_pred, title=None):\n",
    "    print(\"Classification report for: \" + (\"\" if (title == None) else title))\n",
    "    cm = confusion_matrix(y_eval, y_pred)\n",
    "    print(\"Confusion matrix\")\n",
    "    display(pd.DataFrame(cm,columns=['human','AI'],index = ['predicted human','predicted AI']))\n",
    "    print(f\"Metrics:\\n\\taccuracy: {accuracy_score(y_eval, y_pred)}\\n\\tprecision: {precision_score(y_eval, y_pred)}\\n\\trecall: {recall_score(y_eval,y_pred)}\\n\\tF1: {f1_score(y_eval,y_pred)}\")\n",
    "    print(\"Misclassified samples:\")\n",
    "    display(test[y_eval != y_pred][['text', 'source', 'topic', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:08:59.600228Z",
     "iopub.status.busy": "2024-02-05T02:08:59.599814Z",
     "iopub.status.idle": "2024-02-05T02:09:09.693814Z",
     "shell.execute_reply": "2024-02-05T02:09:09.692852Z",
     "shell.execute_reply.started": "2024-02-05T02:08:59.600198Z"
    },
    "id": "GdeKrbDTpyFY",
    "outputId": "40392352-21d1-4e5e-c357-b15d1ada32d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 4s 23ms/step\n",
      "149/149 [==============================] - 4s 26ms/step\n",
      "Classification report for: LSTM with no attention, 64 dim. embedding, 64 units, dropout = 0.2\n",
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted human</th>\n",
       "      <td>2406</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted AI</th>\n",
       "      <td>11</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 human    AI\n",
       "predicted human   2406     8\n",
       "predicted AI        11  2324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\taccuracy: 0.9959991577174142\n",
      "\tprecision: 0.9965694682675815\n",
      "\trecall: 0.995289079229122\n",
      "\tF1: 0.9959288622241268\n",
      "Misclassified samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Man with the Golden Arm, Otto Preminger's ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Now I'm 20 years old. When I was 12, I was mol...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>My boyfriend's(M20) insensitive response to my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>I (31f) and my boyfriend (33m) have been toget...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>After an argument, my [31f] live-in boyfriend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>In mathematics, two quantities are in the gold...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Golden ratio</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>The Ku Klux Klan, commonly shortened to the KK...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Ku Klux Klan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>The Western Electric hand telephone sets compr...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Model 102 telephone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>From its origin as a city-state on the peninsu...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Campaign history of the Roman military</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Physical therapy (PT), also known as physiothe...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Physiotherapy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>A few days ago, I was having a conversation wi...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for saying black dont crack as a non blac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>My sister and I have always had a rocky relati...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA For threatening to leave my sisters dog a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>Throwaway account because I don't want this li...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for telling off my MIL for insisting my d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>Talatat are small stone blocks used in ancient...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Talatat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>Amenemhat I, also known as Ammenemes I or Amen...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Amenemhat I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>Merenre Nemtyemsaf I, also known as Merenre I ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Merenre Nemtyemsaf I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>Senakhtenre Ahmose was an ancient Egyptian pha...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Senakhtenre Ahmose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>The Frisian languages, also known as West Fris...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Frisian languages</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>The Hikurangi Margin, also known as the Hikura...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Hikurangi Margin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>An ion, in the field of chemistry, refers to a...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Ion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>Biocatalysis refers to the use of naturally oc...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Biocatalysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "108   The Man with the Golden Arm, Otto Preminger's ...   \n",
       "843   Now I'm 20 years old. When I was 12, I was mol...   \n",
       "856   I (31f) and my boyfriend (33m) have been toget...   \n",
       "1633  In mathematics, two quantities are in the gold...   \n",
       "1989  The Ku Klux Klan, commonly shortened to the KK...   \n",
       "2087  The Western Electric hand telephone sets compr...   \n",
       "2183  From its origin as a city-state on the peninsu...   \n",
       "2242  Physical therapy (PT), also known as physiothe...   \n",
       "3695  A few days ago, I was having a conversation wi...   \n",
       "3704  My sister and I have always had a rocky relati...   \n",
       "3751  Throwaway account because I don't want this li...   \n",
       "3942  Talatat are small stone blocks used in ancient...   \n",
       "3947  Amenemhat I, also known as Ammenemes I or Amen...   \n",
       "3952  Merenre Nemtyemsaf I, also known as Merenre I ...   \n",
       "3955  Senakhtenre Ahmose was an ancient Egyptian pha...   \n",
       "4525  The Frisian languages, also known as West Fris...   \n",
       "4660  The Hikurangi Margin, also known as the Hikura...   \n",
       "4675  An ion, in the field of chemistry, refers to a...   \n",
       "4739  Biocatalysis refers to the use of naturally oc...   \n",
       "\n",
       "                     source  \\\n",
       "108                    imdb   \n",
       "843   r/relationship_advice   \n",
       "856   r/relationship_advice   \n",
       "1633              wikipedia   \n",
       "1989              wikipedia   \n",
       "2087              wikipedia   \n",
       "2183              wikipedia   \n",
       "2242              wikipedia   \n",
       "3695       GPT reddit posts   \n",
       "3704       GPT reddit posts   \n",
       "3751       GPT reddit posts   \n",
       "3942       wikipedia by GPT   \n",
       "3947       wikipedia by GPT   \n",
       "3952       wikipedia by GPT   \n",
       "3955       wikipedia by GPT   \n",
       "4525       wikipedia by GPT   \n",
       "4660       wikipedia by GPT   \n",
       "4675       wikipedia by GPT   \n",
       "4739       wikipedia by GPT   \n",
       "\n",
       "                                                  topic  label  \n",
       "108                                        movie review      0  \n",
       "843   My boyfriend's(M20) insensitive response to my...      0  \n",
       "856   After an argument, my [31f] live-in boyfriend ...      0  \n",
       "1633                                       Golden ratio      0  \n",
       "1989                                       Ku Klux Klan      0  \n",
       "2087                                Model 102 telephone      0  \n",
       "2183             Campaign history of the Roman military      0  \n",
       "2242                                      Physiotherapy      0  \n",
       "3695  AITA for saying black dont crack as a non blac...      1  \n",
       "3704  AITA For threatening to leave my sisters dog a...      1  \n",
       "3751  AITA for telling off my MIL for insisting my d...      1  \n",
       "3942                                            Talatat      1  \n",
       "3947                                        Amenemhat I      1  \n",
       "3952                               Merenre Nemtyemsaf I      1  \n",
       "3955                                 Senakhtenre Ahmose      1  \n",
       "4525                                  Frisian languages      1  \n",
       "4660                                   Hikurangi Margin      1  \n",
       "4675                                                Ion      1  \n",
       "4739                                       Biocatalysis      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: FF with sdp attention, 64 dim. embedding, 64 units, dropout = 0.5\n",
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted human</th>\n",
       "      <td>2405</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted AI</th>\n",
       "      <td>7</td>\n",
       "      <td>2328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 human    AI\n",
       "predicted human   2405     9\n",
       "predicted AI         7  2328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\taccuracy: 0.9966308696567698\n",
      "\tprecision: 0.9961489088575096\n",
      "\trecall: 0.9970021413276231\n",
      "\tF1: 0.9965753424657535\n",
      "Misclassified samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It would be unwise to judge that that either n...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Man with the Golden Arm, Otto Preminger's ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Chi-hwa-seong (Painted Fire) recounts the life...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>I viewed this movie for the first time last ni...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Now I'm 20 years old. When I was 12, I was mol...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>My boyfriend's(M20) insensitive response to my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>How to Balance Gaming and Relationship Dynamic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Internet identity (IID), also online identity,...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Online identity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>From its origin as a city-state on the peninsu...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Campaign history of the Roman military</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Physical therapy (PT), also known as physiothe...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Physiotherapy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>Throwaway account because I don't want this li...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for telling off my MIL for insisting my d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>My ex-wife recently came out as transgender an...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for asking my transsexual ex-wife to dres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>A cow, scientifically known as Bos taurus, is ...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Cow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>The United States Medical Licensing Examinatio...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>USMLE Step 3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>A gamete, derived from the Greek word gametḗ m...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Gamete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>The Hikurangi Margin, also known as the Hikura...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Hikurangi Margin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>Axial chirality refers to a unique characteris...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Axial chirality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "1     It would be unwise to judge that that either n...   \n",
       "108   The Man with the Golden Arm, Otto Preminger's ...   \n",
       "337   Chi-hwa-seong (Painted Fire) recounts the life...   \n",
       "351   I viewed this movie for the first time last ni...   \n",
       "843   Now I'm 20 years old. When I was 12, I was mol...   \n",
       "954   Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...   \n",
       "1794  Internet identity (IID), also online identity,...   \n",
       "2183  From its origin as a city-state on the peninsu...   \n",
       "2242  Physical therapy (PT), also known as physiothe...   \n",
       "3751  Throwaway account because I don't want this li...   \n",
       "3870  My ex-wife recently came out as transgender an...   \n",
       "4475  A cow, scientifically known as Bos taurus, is ...   \n",
       "4580  The United States Medical Licensing Examinatio...   \n",
       "4653  A gamete, derived from the Greek word gametḗ m...   \n",
       "4660  The Hikurangi Margin, also known as the Hikura...   \n",
       "4742  Axial chirality refers to a unique characteris...   \n",
       "\n",
       "                     source  \\\n",
       "1                      imdb   \n",
       "108                    imdb   \n",
       "337                    imdb   \n",
       "351                    imdb   \n",
       "843   r/relationship_advice   \n",
       "954   r/relationship_advice   \n",
       "1794              wikipedia   \n",
       "2183              wikipedia   \n",
       "2242              wikipedia   \n",
       "3751       GPT reddit posts   \n",
       "3870       GPT reddit posts   \n",
       "4475       wikipedia by GPT   \n",
       "4580       wikipedia by GPT   \n",
       "4653       wikipedia by GPT   \n",
       "4660       wikipedia by GPT   \n",
       "4742       wikipedia by GPT   \n",
       "\n",
       "                                                  topic  label  \n",
       "1                                          movie review      0  \n",
       "108                                        movie review      0  \n",
       "337                                        movie review      0  \n",
       "351                                        movie review      0  \n",
       "843   My boyfriend's(M20) insensitive response to my...      0  \n",
       "954   How to Balance Gaming and Relationship Dynamic...      0  \n",
       "1794                                    Online identity      0  \n",
       "2183             Campaign history of the Roman military      0  \n",
       "2242                                      Physiotherapy      0  \n",
       "3751  AITA for telling off my MIL for insisting my d...      1  \n",
       "3870  AITA for asking my transsexual ex-wife to dres...      1  \n",
       "4475                                                Cow      1  \n",
       "4580                                       USMLE Step 3      1  \n",
       "4653                                             Gamete      1  \n",
       "4660                                   Hikurangi Margin      1  \n",
       "4742                                    Axial chirality      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "models.append(load_model(get_model_path(64, 0, 1, None, 64, .2) + '_continued_on_full_3'))\n",
    "models.append(load_model(get_model_path(64, 1, 0, 'sdp', 64, .5) + '_continued_on_full_3'))\n",
    "\n",
    "y_probas = [np.transpose(model.predict(X_test))[1] for model in models]\n",
    "y_preds = [y_proba > .5 for y_proba in y_probas]\n",
    "\n",
    "display_results(y_test, y_preds[0], title='LSTM with no attention, 64 dim. embedding, 64 units, dropout = 0.2')\n",
    "display_results(y_test, y_preds[1], title='FF with sdp attention, 64 dim. embedding, 64 units, dropout = 0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore methods for improving model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XShcKRZat-mn"
   },
   "source": [
    "We actually see that the top two models have misclassified different sets of samples. This suggests that we could use an ensemble classifier to improve the accuracy, since each model might have specific weaknesses that can be compensated for by incorporating the predictions of others. We will combine the top 4 performing models on the validation set after 12 epochs of further training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:09:40.936444Z",
     "iopub.status.busy": "2024-02-05T02:09:40.935555Z",
     "iopub.status.idle": "2024-02-05T02:09:40.941818Z",
     "shell.execute_reply": "2024-02-05T02:09:40.940749Z",
     "shell.execute_reply.started": "2024-02-05T02:09:40.936409Z"
    },
    "id": "hr1qPCOYBPwA"
   },
   "outputs": [],
   "source": [
    "class SoftVoterAIDetector:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_probas = [model.predict(X) for model in self.models]\n",
    "        return np.mean(y_probas, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:11:19.168152Z",
     "iopub.status.busy": "2024-02-05T02:11:19.167416Z",
     "iopub.status.idle": "2024-02-05T02:11:23.154457Z",
     "shell.execute_reply": "2024-02-05T02:11:23.153619Z",
     "shell.execute_reply.started": "2024-02-05T02:11:19.168119Z"
    },
    "id": "CUNqKpuyL9PB"
   },
   "outputs": [],
   "source": [
    "models.append(load_model(get_model_path(16, 0, 1, None, 64, .2) + '_continued_on_full_3'))\n",
    "models.append(load_model(get_model_path(64, 0, 1, None, 64, .5) + '_continued_on_full_3'))\n",
    "\n",
    "clf = SoftVoterAIDetector(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:11:41.087985Z",
     "iopub.status.busy": "2024-02-05T02:11:41.086960Z",
     "iopub.status.idle": "2024-02-05T02:11:56.877919Z",
     "shell.execute_reply": "2024-02-05T02:11:56.876185Z",
     "shell.execute_reply.started": "2024-02-05T02:11:41.087951Z"
    },
    "id": "j0STMa3EOjkE",
    "outputId": "b33e91e3-7e2f-4644-89b8-ca0d8e7a90a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 3s 23ms/step\n",
      "149/149 [==============================] - 4s 27ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "149/149 [==============================] - 4s 22ms/step\n",
      "Classification report for: soft voting classifier\n",
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted human</th>\n",
       "      <td>2409</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted AI</th>\n",
       "      <td>3</td>\n",
       "      <td>2332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 human    AI\n",
       "predicted human   2409     5\n",
       "predicted AI         3  2332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\taccuracy: 0.9983154348283849\n",
      "\tprecision: 0.9978605049208387\n",
      "\trecall: 0.9987152034261242\n",
      "\tF1: 0.9982876712328766\n",
      "Misclassified samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Man with the Golden Arm, Otto Preminger's ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Now I'm 20 years old. When I was 12, I was mol...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>My boyfriend's(M20) insensitive response to my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>I (31f) and my boyfriend (33m) have been toget...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>After an argument, my [31f] live-in boyfriend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>How to Balance Gaming and Relationship Dynamic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Physical therapy (PT), also known as physiothe...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Physiotherapy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>A few days ago, I was having a conversation wi...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for saying black dont crack as a non blac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>Throwaway account because I don't want this li...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for telling off my MIL for insisting my d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>The Hikurangi Margin, also known as the Hikura...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Hikurangi Margin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "108   The Man with the Golden Arm, Otto Preminger's ...   \n",
       "843   Now I'm 20 years old. When I was 12, I was mol...   \n",
       "856   I (31f) and my boyfriend (33m) have been toget...   \n",
       "954   Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...   \n",
       "2242  Physical therapy (PT), also known as physiothe...   \n",
       "3695  A few days ago, I was having a conversation wi...   \n",
       "3751  Throwaway account because I don't want this li...   \n",
       "4660  The Hikurangi Margin, also known as the Hikura...   \n",
       "\n",
       "                     source  \\\n",
       "108                    imdb   \n",
       "843   r/relationship_advice   \n",
       "856   r/relationship_advice   \n",
       "954   r/relationship_advice   \n",
       "2242              wikipedia   \n",
       "3695       GPT reddit posts   \n",
       "3751       GPT reddit posts   \n",
       "4660       wikipedia by GPT   \n",
       "\n",
       "                                                  topic  label  \n",
       "108                                        movie review      0  \n",
       "843   My boyfriend's(M20) insensitive response to my...      0  \n",
       "856   After an argument, my [31f] live-in boyfriend ...      0  \n",
       "954   How to Balance Gaming and Relationship Dynamic...      0  \n",
       "2242                                      Physiotherapy      0  \n",
       "3695  AITA for saying black dont crack as a non blac...      1  \n",
       "3751  AITA for telling off my MIL for insisting my d...      1  \n",
       "4660                                   Hikurangi Margin      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba_softvote = np.transpose(clf.predict(X_test))[1]\n",
    "\n",
    "display_results(y_test, y_proba_softvote > .5, title='soft voting classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epHjU4vFWokO"
   },
   "source": [
    "We see that an accuracy of higher than 99.8% can be achieved, with only 8 misclassified samples. Finally, we will see if adjusting the threshold probability will improve the accuracy of the model. We will use the validation set to hyperparameter tune the threshold probability, and plot the accuracy, precision, recall and F1 scores as a function of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:12:22.890734Z",
     "iopub.status.busy": "2024-02-05T02:12:22.889978Z",
     "iopub.status.idle": "2024-02-05T02:12:22.904139Z",
     "shell.execute_reply": "2024-02-05T02:12:22.903168Z",
     "shell.execute_reply.started": "2024-02-05T02:12:22.890704Z"
    },
    "id": "Zn0YJxzIWpx2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(y_test, y_proba, report_max = False, title='metrics vs threshold'):\n",
    "    thresholds = [y_proba[i] - 1e-6 for i in range(len(y_proba))]\n",
    "    thresholds.sort()   # thresholds = [0, .11, .24, ...]\n",
    "    y_preds = [y_proba > thresholds[i] for i in range(len(thresholds))] # y_preds = [predicted_1, predicted_2, predicted_#, ...]\n",
    "    metrics = [(accuracy_score(y_test, y_preds[i]), precision_score(y_test, y_preds[i]), recall_score(y_test, y_preds[i]), f1_score(y_test, y_preds[i])) for i in range(len(y_test))]\n",
    "    s1 = [metrics[i][0] for i in range(len(y_test))]\n",
    "    s2 = [metrics[i][1] for i in range(len(y_test))]\n",
    "    s3 = [metrics[i][2] for i in range(len(y_test))]\n",
    "    s4 = [metrics[i][3] for i in range(len(y_test))]\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(thresholds, s1, label='accuracy')\n",
    "    plt.plot(thresholds, s2, label='precision')\n",
    "    plt.plot(thresholds, s3, label='recall')\n",
    "    plt.plot(thresholds, s4, label='F1')\n",
    "\n",
    "    plt.xlabel('threshold')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    if report_max:\n",
    "        reports = []\n",
    "        reports.append({'metric':'accuracy', 'threshold': thresholds[s1.index(max(s1))], 'maximum': max(s1)})\n",
    "        reports.append({'metric':'precision', 'threshold': thresholds[s2.index(max(s2))], 'maximum': max(s2)})\n",
    "        reports.append({'metric':'recall', 'threshold': thresholds[s3.index(max(s3))], 'maximum': max(s3)})\n",
    "        reports.append({'metric':'F1', 'threshold': thresholds[s4.index(max(s4))], 'maximum': max(s4)})\n",
    "\n",
    "        return pd.DataFrame(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:12:29.169381Z",
     "iopub.status.busy": "2024-02-05T02:12:29.169003Z",
     "iopub.status.idle": "2024-02-05T02:13:08.174247Z",
     "shell.execute_reply": "2024-02-05T02:13:08.173318Z",
     "shell.execute_reply.started": "2024-02-05T02:12:29.169352Z"
    },
    "id": "P6wcHihzY8kw",
    "outputId": "e7d596c1-5fda-482c-e25a-308da95c0bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 3s 24ms/step\n",
      "121/121 [==============================] - 3s 25ms/step\n",
      "121/121 [==============================] - 3s 22ms/step\n",
      "121/121 [==============================] - 3s 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>maximum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>4.777347e-01</td>\n",
       "      <td>0.998439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>9.007957e-01</td>\n",
       "      <td>0.999472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>-9.997581e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>4.777347e-01</td>\n",
       "      <td>0.998429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              threshold   maximum\n",
       "metric                           \n",
       "accuracy   4.777347e-01  0.998439\n",
       "precision  9.007957e-01  0.999472\n",
       "recall    -9.997581e-07  1.000000\n",
       "F1         4.777347e-01  0.998429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val_proba = np.transpose(clf.predict(X_val))[1]\n",
    "report_metrics = plot_metrics(np.transpose(y_val)[1], y_val_proba, report_max=True)\n",
    "report_metrics.set_index('metric', inplace=True)\n",
    "display(report_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T02:13:18.379911Z",
     "iopub.status.busy": "2024-02-05T02:13:18.379035Z",
     "iopub.status.idle": "2024-02-05T02:13:18.411565Z",
     "shell.execute_reply": "2024-02-05T02:13:18.410516Z",
     "shell.execute_reply.started": "2024-02-05T02:13:18.379877Z"
    },
    "id": "m9K__TeWwNId",
    "outputId": "858d1874-d531-401d-8256-2c8e33a4b096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for: softvoter with threshold = 0.47773\n",
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>AI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predicted human</th>\n",
       "      <td>2409</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted AI</th>\n",
       "      <td>3</td>\n",
       "      <td>2332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 human    AI\n",
       "predicted human   2409     5\n",
       "predicted AI         3  2332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\taccuracy: 0.9983154348283849\n",
      "\tprecision: 0.9978605049208387\n",
      "\trecall: 0.9987152034261242\n",
      "\tF1: 0.9982876712328766\n",
      "Misclassified samples:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>The Man with the Golden Arm, Otto Preminger's ...</td>\n",
       "      <td>imdb</td>\n",
       "      <td>movie review</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Now I'm 20 years old. When I was 12, I was mol...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>My boyfriend's(M20) insensitive response to my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>I (31f) and my boyfriend (33m) have been toget...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>After an argument, my [31f] live-in boyfriend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...</td>\n",
       "      <td>r/relationship_advice</td>\n",
       "      <td>How to Balance Gaming and Relationship Dynamic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Physical therapy (PT), also known as physiothe...</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>Physiotherapy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>A few days ago, I was having a conversation wi...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for saying black dont crack as a non blac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>Throwaway account because I don't want this li...</td>\n",
       "      <td>GPT reddit posts</td>\n",
       "      <td>AITA for telling off my MIL for insisting my d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>The Hikurangi Margin, also known as the Hikura...</td>\n",
       "      <td>wikipedia by GPT</td>\n",
       "      <td>Hikurangi Margin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "108   The Man with the Golden Arm, Otto Preminger's ...   \n",
       "843   Now I'm 20 years old. When I was 12, I was mol...   \n",
       "856   I (31f) and my boyfriend (33m) have been toget...   \n",
       "954   Hey Reddit,\\n\\nI'm  in a bit of a pickle with ...   \n",
       "2242  Physical therapy (PT), also known as physiothe...   \n",
       "3695  A few days ago, I was having a conversation wi...   \n",
       "3751  Throwaway account because I don't want this li...   \n",
       "4660  The Hikurangi Margin, also known as the Hikura...   \n",
       "\n",
       "                     source  \\\n",
       "108                    imdb   \n",
       "843   r/relationship_advice   \n",
       "856   r/relationship_advice   \n",
       "954   r/relationship_advice   \n",
       "2242              wikipedia   \n",
       "3695       GPT reddit posts   \n",
       "3751       GPT reddit posts   \n",
       "4660       wikipedia by GPT   \n",
       "\n",
       "                                                  topic  label  \n",
       "108                                        movie review      0  \n",
       "843   My boyfriend's(M20) insensitive response to my...      0  \n",
       "856   After an argument, my [31f] live-in boyfriend ...      0  \n",
       "954   How to Balance Gaming and Relationship Dynamic...      0  \n",
       "2242                                      Physiotherapy      0  \n",
       "3695  AITA for saying black dont crack as a non blac...      1  \n",
       "3751  AITA for telling off my MIL for insisting my d...      1  \n",
       "4660                                   Hikurangi Margin      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = report_metrics.loc['accuracy', 'threshold']\n",
    "display_results(y_test, y_proba_softvote > threshold, title='softvoter with threshold = %.5f'%threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold for maximising accuracy is very close to 0.5, so we are unable to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and concluding remarks\n",
    "\n",
    "We have seen that small language models (only several MB in size) are extraordinarily effective in detecting whether a text was generated by GPT-3.5 Turbo. We explored the use of LSTMs and various attention mechanisms with different dropout rates (0.2, 0.5), embedding dimensions (16, 64) and layer sizes (16, 64), ultimately generating test results for 144 different models. Surprisingly, a basic feedforward network with 16 neurons, no attention layer and embedding dimension of 16 attained an accuracy of over 99.6%, which shows that the challenge is primarily driven by the quality of the training data, rather than the complexity of the model or the use of advanced natural language processing techniques. Nevertheless, we saw a significant increase in accuracy with an ensemble classifier incorporating more complex models, but further testing will be required to determine whether this is statistically significant.\n",
    "\n",
    "In the model evaluation process, I only used a single validation set consisting of 20% of the training data and focused on comparing the performance of a large range of models. However this evaluation could be improved by using five-fold cross validation instead. More detailed learning rate scheduling for the individual models might also slightly improve performance, since across the 144 different models, only three different learning rate schedulers were used.\n",
    "\n",
    "Finally I will note that the training data was also quite limited, since only three sources were used for the human data and one large language model for the AI generated data, with minimal prompt engineering. Further testing will be needed to determine how well the models will generalise to text obtained from other sources. While we have trained the models on texts from thousands of different human writers, we have only exposed them to a single LLM, in a sense, with a single \"personality,\" which we have interfaced with via an API. It is probable that much of future AI generated text will be obtained through a web interface, with adjustable chat settings such as temperature, content and language restrictions, the type of emotions or sentiment desired in the output, and even sociolinguistic specificities or levels of imitation of various human writers or celebrity figures. Thus it will be necessary to broaden the parameters of LLM output to improve the generalisation of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4394796,
     "sourceId": 7546263,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
